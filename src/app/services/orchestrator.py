# src/app/services/orchestrator.py

import asyncio
import json
from typing import List, Dict, Tuple
from fastapi import UploadFile

from beanie.operators import In
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.prompts import ChatPromptTemplate

from app.core.config import settings, logger
from app.models.discussion import AgentSettings, AgentConfig, SystemSettings

from app.schemas.orchestration import (
    IssueAnalysisReport, 
    CoreEvidenceBriefing, 
    EvidenceItem,
    SelectedJury,
    DebateTeam,
    AgentDetail
)

from app.tools.search import perform_web_search_async
from app.services.document_processor import process_uploaded_file
from app.services.summarizer import summarize_text
from app import db

# --- ì—­í•  ê¸°ë°˜ ìƒìˆ˜ ì •ì˜ ---
JUDGE_AGENT_NAME = "ì¬íŒê´€"
CRITICAL_AGENT_NAME = "ë¹„íŒì  ê´€ì "
TOPIC_ANALYST_NAME = "Topic Analyst"
JURY_SELECTOR_NAME = "Jury Selector"

# --- ì•„ì´ì½˜ ìƒì„±ì„ ìœ„í•œ í—¬í¼ í•¨ìˆ˜ ë° ìƒìˆ˜ ---
ICON_MAP = {
    # ì—­í• /ì§ì—…
    "ì¬íŒê´€": "ğŸ§‘", "ë¶„ì„ê°€": "ğŸ“Š", "ê²½ì œ": "ğŸŒ", "ì‚°ì—…": "ğŸ­", "ì¬ë¬´": "ğŸ’¹",
    "íŠ¸ë Œë“œ": "ğŸ“ˆ", "ë¹„íŒ": "ğŸ¤”", "ì „ë¬¸ê°€": "ğŸ§‘", "ë¯¸ì‹œ": "ğŸ›’", "ë¯¸ë˜í•™ì": "ğŸ”­",
    "ë¬¼ë¦¬í•™": "âš›ï¸", "ì–‘ì": "ğŸŒ€", "ì˜í•™": "âš•ï¸", "ì‹¬ë¦¬í•™": "ğŸ§ ", "ë‡Œê³¼í•™": "âš¡ï¸",
    "ë¬¸í•™": "âœï¸", "ì—­ì‚¬": "ğŸ›ï¸", "ìƒë¬¼í•™": "ğŸ§¬", "ë²•ì˜í•™": "ğŸ”¬", "ë²•ë¥ ": "âš–ï¸",
    "íšŒê³„": "ğŸ§¾", "ì¸ì‚¬": "ğŸ‘¥", "ì¸ë¥˜í•™": "ğŸ—¿", "IT": "ğŸ’»", "ê°œë°œ": "ğŸ‘¨â€ğŸ’»",
    # ê³ ìœ ëª…ì‚¬/ì¸ë¬¼
    "ë²„í•": "ğŸ‘´", "ë¦°ì¹˜": "ğŸ‘¨â€ğŸ’¼", "ì¡ìŠ¤": "ğŸ’¡", "ë¨¸ìŠ¤í¬": "ğŸš€", "ë² ì´ì¡°ìŠ¤": "ğŸ“¦",
    "ì›°ì¹˜": "ğŸ†", "ì•„ì¸ìŠˆíƒ€ì¸": "ğŸŒŒ",
    # ê¸°íƒ€ í‚¤ì›Œë“œ
    "ì„ ì •": "ğŸ“‹", "ë¶„ì„": "ğŸ”"
}
DEFAULT_ICON = "ğŸ§‘"

def _get_icon_for_agent(agent_data: dict) -> str:
    """
    ì—ì´ì „íŠ¸ì˜ ì´ë¦„ê³¼ í”„ë¡¬í”„íŠ¸ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê°€ì¥ ì í•©í•œ ì•„ì´ì½˜ 'í•˜ë‚˜'ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    ì¼ì¹˜í•˜ëŠ” í‚¤ì›Œë“œê°€ ì—¬ëŸ¬ ê°œì¼ ê²½ìš°, ê°€ì¥ ê¸´ í‚¤ì›Œë“œë¥¼ ìš°ì„ í•©ë‹ˆë‹¤.
    """
    name = agent_data.get("name", "")
    prompt = agent_data.get("prompt", "")

    # 1ìˆœìœ„: ì´ë¦„ì—ì„œ ê°€ì¥ ê¸¸ê²Œ ì¼ì¹˜í•˜ëŠ” í‚¤ì›Œë“œ ì°¾ê¸°
    name_matches = [keyword for keyword in ICON_MAP if keyword in name]
    if name_matches:
        best_match = max(name_matches, key=len)
        return ICON_MAP[best_match]

    # 2ìˆœìœ„: í”„ë¡¬í”„íŠ¸ì—ì„œ ê°€ì¥ ê¸¸ê²Œ ì¼ì¹˜í•˜ëŠ” í‚¤ì›Œë“œ ì°¾ê¸°
    prompt_matches = [keyword for keyword in ICON_MAP if keyword in prompt]
    if prompt_matches:
        best_match = max(prompt_matches, key=len)
        return ICON_MAP[best_match]

    # 3ìˆœìœ„: ê¸°ë³¸ ì•„ì´ì½˜ ë°˜í™˜
    return DEFAULT_ICON

# --- DBì—ì„œ Active ìƒíƒœì˜ ì—ì´ì „íŠ¸ë¥¼ ì¡°íšŒí•˜ëŠ” í•¨ìˆ˜ ---
async def get_active_agents_from_db() -> Tuple[Dict[str, Dict], Dict[str, Dict]]:
    """
    DBì—ì„œ 'active' ìƒíƒœì¸ ì—ì´ì „íŠ¸ë“¤ì„ ì¡°íšŒí•˜ì—¬ 'special'ê³¼ 'expert' íƒ€ì…ìœ¼ë¡œ ë¶„ë¦¬í•˜ì—¬ ë°˜í™˜í•©ë‹ˆë‹¤.
    ë°˜í™˜ë˜ëŠ” ë”•ì…”ë„ˆë¦¬ì˜ ê°’(value)ì— 'name' í•„ë“œë¥¼ í¬í•¨ì‹œí‚µë‹ˆë‹¤.
    """
    special_agents = {}
    expert_agents = {}
    
    active_agents_cursor = AgentSettings.find(AgentSettings.status == "active")
    
    async for agent in active_agents_cursor:
        # config ë”•ì…”ë„ˆë¦¬ì™€ nameì„ í•©ì³ì„œ ì™„ì „í•œ ì—ì´ì „íŠ¸ ì •ë³´ ë”•ì…”ë„ˆë¦¬ë¥¼ ìƒì„±
        full_agent_details = {
            "name": agent.name,
            **agent.config.model_dump()
        }
        
        if agent.agent_type == "special":
            special_agents[agent.name] = full_agent_details
        else: # "expert"
            expert_agents[agent.name] = full_agent_details
            
    return special_agents, expert_agents

# --- 1ë‹¨ê³„: ì‚¬ê±´ ë¶„ì„ ---
async def analyze_topic(topic: str, special_agents: Dict[str, Dict], discussion_id: str) -> IssueAnalysisReport:
    print(f"--- [Orchestrator] 1ë‹¨ê³„: ì‚¬ê±´ ë¶„ì„ ì‹œì‘ (ID: {discussion_id}) ---")
    
    analyst_config = special_agents.get(TOPIC_ANALYST_NAME)
    if not analyst_config:
        raise ValueError(f"'{TOPIC_ANALYST_NAME}' ì„¤ì •ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    llm = ChatGoogleGenerativeAI(
        model=analyst_config["model"],
        temperature=analyst_config["temperature"],
        location="asia-northeast3"
    )
    structured_llm = llm.with_structured_output(IssueAnalysisReport)
    
    prompt = ChatPromptTemplate.from_messages([
        ("system", analyst_config["prompt"]),
        ("human", "Please analyze the following topic: {topic}"),
    ])
    
    chain = prompt | structured_llm
    
    # LLM í˜¸ì¶œ ì‹œ configì— íƒœê·¸ ì¶”ê°€
    report = await chain.ainvoke(
        {"topic": topic},
        config={"tags": [f"discussion_id:{discussion_id}"]}
    )
    
    print(f"--- [Orchestrator] 1ë‹¨ê³„: ì‚¬ê±´ ë¶„ì„ ì™„ë£Œ ---")
    return report

# --- ì¦ê±° ìˆ˜ì§‘ ë¡œì§ ---
async def gather_evidence(
    report: IssueAnalysisReport, 
    files: List[UploadFile],
    topic: str,
    discussion_id: str
) -> CoreEvidenceBriefing:
    """
    ë¶„ì„ ë³´ê³ ì„œì™€ ì‚¬ìš©ì íŒŒì¼ì„ ê¸°ë°˜ìœ¼ë¡œ 'í•µì‹¬ ìë£Œì§‘'ì„ ìƒì„±í•©ë‹ˆë‹¤.
    ì›¹ ê²€ìƒ‰ê³¼ íŒŒì¼ ì²˜ë¦¬ë¥¼ ë³‘ë ¬ë¡œ ìˆ˜í–‰í•˜ì—¬ íš¨ìœ¨ì„±ì„ ë†’ì…ë‹ˆë‹¤.
    """
    print(f"--- [Orchestrator] 2ë‹¨ê³„: ì¦ê±° ìˆ˜ì§‘ ì‹œì‘ (ID: {discussion_id}) ---")
    tasks = {
        "web": _get_web_evidence(report, topic, discussion_id),
        "files": _get_file_evidence(files, topic, discussion_id)
    }

    # asyncio.gatherë¥¼ ì‚¬ìš©í•˜ì—¬ ëª¨ë“  ì‘ì—…ì„ ë³‘ë ¬ë¡œ ì‹¤í–‰í•˜ê³  ê²°ê³¼ë¥¼ ê¸°ë‹¤ë¦¼
    results = await asyncio.gather(*tasks.values())
    
    evidence_map = dict(zip(tasks.keys(), results))

    print(f"--- [Orchestrator] 2ë‹¨ê³„: ì¦ê±° ìˆ˜ì§‘ ì™„ë£Œ ---")

    return CoreEvidenceBriefing(
        web_evidence=evidence_map["web"],
        file_evidence=evidence_map["files"]
    )

async def _get_web_evidence(report: IssueAnalysisReport, topic: str, discussion_id: str) -> List[EvidenceItem]:
    search_query = f"{topic}: {', '.join(report.core_keywords)}"
    search_results = await perform_web_search_async(search_query) # ì›¹ ê²€ìƒ‰ ìì²´ëŠ” LLM í˜¸ì¶œì´ ì•„ë‹˜
    
    if not search_results:
        return []

    summary_tasks = [
        # summarize_text í˜¸ì¶œ ì‹œ discussion_id ì „ë‹¬
        summarize_text(result["content"], topic, discussion_id)
        for result in search_results if result.get("content")
    ]
    summaries = await asyncio.gather(*summary_tasks)

    # ìš”ì•½ëœ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ìµœì¢… ì¦ê±° í•­ëª© ìƒì„±
    evidence_items = [
        EvidenceItem(
            source=result.get("url", "Unknown Source"),
            summary=summaries[i]
        )
        for i, result in enumerate(search_results) if result.get("content")
    ]
            
    return evidence_items

async def _get_file_evidence(files: List[UploadFile], topic: str, discussion_id: str) -> List[EvidenceItem]:
    """ì—…ë¡œë“œëœ íŒŒì¼ë“¤ì„ ì²˜ë¦¬í•˜ê³  ìš”ì•½í•˜ì—¬ ì¦ê±° í•­ëª© ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    if not files:
        return []

    # ê° íŒŒì¼ì„ ì½ê³  í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ëŠ” ì‘ì—…ì„ ë³‘ë ¬ë¡œ ì²˜ë¦¬
    processing_tasks = [process_uploaded_file(file) for file in files]
    file_contents = await asyncio.gather(*processing_tasks, return_exceptions=True)

    # íŒŒì¼ ë‚´ìš© ìš”ì•½ ì‘ì—…ì„ ë³‘ë ¬ë¡œ ì²˜ë¦¬
    summary_tasks = [
        # summarize_text í˜¸ì¶œ ì‹œ discussion_id ì „ë‹¬
        summarize_text(content, topic, discussion_id)
        for content in file_contents if isinstance(content, str)
    ]
    summaries = await asyncio.gather(*summary_tasks)

    # ìš”ì•½ëœ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ìµœì¢… ì¦ê±° í•­ëª© ìƒì„±
    evidence_items = [
        EvidenceItem(
            source=files[i].filename,
            summary=summaries[i]
        )
        for i, content in enumerate(file_contents) if isinstance(content, str)
    ]
        
    return evidence_items

# --- ë°°ì‹¬ì›ë‹¨ ì„ ì • ë¡œì§ ---
def _load_available_agents() -> List[Dict[str, str]]:
    """
    ì„ íƒ ê°€ëŠ¥í•œ ì—ì´ì „íŠ¸ í’€ì„ ì„¤ì • íŒŒì¼ì—ì„œ ë¡œë“œí•©ë‹ˆë‹¤.
    'ì¬íŒê´€'ê³¼ ê°™ì€ íŠ¹ìˆ˜ ì—­í• ì€ ì´ í’€ì—ì„œ ì œì™¸ë©ë‹ˆë‹¤.
    """
    try:
        # ì´ ê²½ë¡œëŠ” src/app/core/settings/agents.jsonì„ ê°€ë¦¬í‚µë‹ˆë‹¤.
        # í•´ë‹¹ ìœ„ì¹˜ë¡œ agents.json íŒŒì¼ì„ ì´ë™ì‹œì¼œì•¼ í•©ë‹ˆë‹¤.
        with open("app/core/settings/agents.json", "r", encoding="utf-8") as f:
            all_agents = json.load(f).get("agents", [])
            return [agent for agent in all_agents if agent.get("name") != JUDGE_AGENT_NAME]
    except FileNotFoundError:
        raise ValueError("ì—ì´ì „íŠ¸ ì„¤ì • íŒŒì¼(app/core/settings/agents.json)ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

async def select_debate_team(report: IssueAnalysisReport, jury_pool: Dict, special_agents: Dict, discussion_id: str) -> DebateTeam:
    """
    ë¶„ì„ ë³´ê³ ì„œë¥¼ ê¸°ë°˜ìœ¼ë¡œ AI ë°°ì‹¬ì›ë‹¨ì„ ì„ ì •í•˜ê³ , í•„ìš” ì‹œ ìƒˆë¡œìš´ ì—ì´ì „íŠ¸ë¥¼ ìƒì„±í•œ í›„ ì¬íŒê´€ì„ ì§€ì •í•©ë‹ˆë‹¤.
    """
    print(f"--- [Orchestrator] 3ë‹¨ê³„: ë°°ì‹¬ì›ë‹¨ ì„ ì • ì‹œì‘ (ID: {discussion_id}) ---")

    selector_config = special_agents.get(JURY_SELECTOR_NAME)
    if not selector_config:
        raise ValueError(f"'{JURY_SELECTOR_NAME}' ì„¤ì •ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    agent_pool_description_list = [
        f"- {name}: {config['prompt'].split('.')[0]}."
        for name, config in jury_pool.items()
    ]
    agent_pool_description = "\n".join(agent_pool_description_list)

    system_prompt = f"""
    You are a master moderator and an expert talent scout assembling a panel of AI experts for a debate. Your primary goal is to create the most insightful and diverse debate panel possible for the given topic.

    **Your Tasks:**
    1.  **Select from Existing Experts:** From the `Available Expert Agents Pool`, select the 4 to 6 most relevant experts.
    2.  **Propose New Experts:** Critically evaluate your selection. If you believe a crucial perspective is missing, propose 1 to 2 new, highly specific expert roles that do not exist in the current pool. The proposed role names must be in KOREAN. **The names should be concise and simple, without any parentheses or repeated phrases (e.g., use 'ì—¬ë¡ ì¡°ì‚¬ ì „ë¬¸ê°€', not 'ì—¬ë¡ ì¡°ì‚¬ ì „ë¬¸ê°€(ì—¬ë¡ ì¡°ì‚¬ ì „ë¬¸ê°€)').**
    3.  **Provide Justification:** Write a concise reason explaining your selections and any new proposals, detailing why this specific combination of experts is optimal for the given debate topic. The justification must be written in KOREAN.

    **Available Expert Agents Pool (Name: Role Summary):**
    {agent_pool_description}

    You must only respond with a single, valid JSON object that strictly adheres to the required schema.
    """

    llm = ChatGoogleGenerativeAI(
        model=selector_config["model"],
        temperature=selector_config["temperature"]
    )
    structured_llm = llm.with_structured_output(SelectedJury)

    prompt = ChatPromptTemplate.from_messages([
        ("system", system_prompt),
        ("human", "Here is the debate context (Issue Analysis Report):\n\n{report_json}")
    ])

    chain = prompt | structured_llm
    selected_jury: SelectedJury = await chain.ainvoke(
        {"report_json": report.model_dump_json(indent=2)},
        config={"tags": [f"discussion_id:{discussion_id}", f"agent_name:{JURY_SELECTOR_NAME}"]}
    )

    # í•˜ë“œì½”ë”©ëœ í”„ë¡¬í”„íŠ¸ ëŒ€ì‹  DBì—ì„œ ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤.
    db_name = settings.MONGO_DB_URL.split("/")[-1].split("?")[0]
    settings_collection = db.mongo_client[db_name]["system_settings"]
    default_prompt_setting = await settings_collection.find_one({"key": "default_agent_prompt"})
    
    PROMPT_TEMPLATE = (
        "ë‹¹ì‹ ì˜ ì—­í• ì€ '{role}'ì´ë©° ì§€ì •ëœ ì—­í•  ê´€ì ì—ì„œ ë§í•˜ì„¸ìš”.\n"
        "ë‹¹ì‹ ì˜ ì—­í• ì— ë§ëŠ” ëŒ€í™”ìŠ¤íƒ€ì¼ì„ ì‚¬ìš©í•˜ì„¸ìš”.\n"
        "í† ì˜ ê·œì¹™ì„ ìˆ™ì§€í•˜ê³  í† ë¡ ì˜ ëª©í‘œë¥¼ ë‹¬ì„±í•˜ê¸° ìœ„í•´ ì œì‹œëœ ì˜ê²¬ë“¤ì„ ë°”íƒ•ìœ¼ë¡œ ë³´ì™„ì˜ê²¬ì„ ì œì‹œí•˜ê±°ë‚˜, ì£¼ì¥ì„ ê°•í™”,ì² íšŒ,ìˆ˜ì • í•˜ì„¸ìš”.\n"
        "ëª¨ë“  ì˜ê²¬ì€ ë…¼ë¦¬ì ì´ê³  ì¼ê´€ì„±ì´ ìˆì–´ì•¼ í•˜ë©° ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì¶œì²˜ì— ê¸°ë°˜í•´ì•¼í•˜ê³  ìì„¸í•˜ê²Œ ë‹µë³€í•˜ì—¬ì•¼ í•©ë‹ˆë‹¤.\n"
        "ì‚¬ìš©ìê°€ ì§ˆë¬¸í•œ ì–¸ì–´ë¡œ ë‹µë³€í•˜ì—¬ì•¼ í•©ë‹ˆë‹¤."
    )
    
    if default_prompt_setting and default_prompt_setting.get("value"):
        PROMPT_TEMPLATE = default_prompt_setting["value"]
        logger.info("--- [Orchestrator] DBì—ì„œ ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ë¥¼ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œí–ˆìŠµë‹ˆë‹¤. ---")
    else:
        logger.info("--- [Orchestrator] DBì— ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ ì„¤ì •ì´ ì—†ì–´ ê¸°ë³¸ê°’ìœ¼ë¡œ ìƒì„±í•©ë‹ˆë‹¤. ---")
        # Beanie ëŒ€ì‹  motor ë“œë¼ì´ë²„ë¥¼ ì‚¬ìš©í•˜ì—¬ DBì— ì €ì¥
        await settings_collection.update_one(
            {"key": "default_agent_prompt"},
            {"$set": {
                "value": PROMPT_TEMPLATE,
                "description": "Jury Selectorê°€ ë™ì ìœ¼ë¡œ ì—ì´ì „íŠ¸ë¥¼ ìƒì„±í•  ë•Œ ì‚¬ìš©í•˜ëŠ” ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿. '{role}' ë³€ìˆ˜ë¥¼ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤."
            }},
            upsert=True
        )

    newly_created_agents = []
    if selected_jury.new_agent_proposals:
        for agent_name in selected_jury.new_agent_proposals:
            existing_agent = await AgentSettings.find_one(AgentSettings.name == agent_name)
            if not existing_agent:
                agent_prompt = PROMPT_TEMPLATE.format(role=agent_name)

                agent_info_for_icon = {"name": agent_name, "prompt": agent_prompt}
                selected_icon = _get_icon_for_agent(agent_info_for_icon)

                # ì‹ ê·œ ì—ì´ì „íŠ¸ ì„¤ì •ì—ì„œ 'tools' í•„ë“œ ì™„ì „ ì‚­ì œ
                new_agent_config = AgentConfig(
                    prompt=agent_prompt,
                    model="gemini-1.5-pro",
                    temperature=0.3,
                    icon=selected_icon
                )

                new_agent = AgentSettings(
                    name=agent_name,
                    agent_type="expert",
                    version=1,
                    status="active",
                    config=new_agent_config,
                    last_modified_by="Jury_Selector_AI",
                    discussion_participation_count=0
                )
                await new_agent.insert()
                print(f"--- [Orchestrator] ì‹ ê·œ ì—ì´ì „íŠ¸ ìƒì„± ë° DB ì €ì¥ ì™„ë£Œ: {agent_name} (Icon: {selected_icon}) ---")

                newly_created_agents.append(AgentDetail(**{"name": agent_name, **new_agent_config.model_dump()}))

    final_jury_details = [AgentDetail(**jury_pool[name]) for name in selected_jury.selected_agents if name in jury_pool]
    final_jury_details.extend(newly_created_agents)

    if CRITICAL_AGENT_NAME in jury_pool and not any(agent.name == CRITICAL_AGENT_NAME for agent in final_jury_details):
        print(f"--- [ê·œì¹™ ì ìš©] '{CRITICAL_AGENT_NAME}'ì´ ëˆ„ë½ë˜ì–´ ê°•ì œë¡œ ì¶”ê°€í•©ë‹ˆë‹¤. ---")
        final_jury_details.append(AgentDetail(**jury_pool[CRITICAL_AGENT_NAME]))

    final_jury_names = [agent.name for agent in final_jury_details]
    if final_jury_names:
        await AgentSettings.find_many(
            In(AgentSettings.name, final_jury_names)
        ).update({"$inc": {AgentSettings.discussion_participation_count: 1}})
        print(f"--- [Orchestrator] ì°¸ì—¬ ì—ì´ì „íŠ¸ ì¹´ìš´íŠ¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ: {final_jury_names} ---")

    judge_config = special_agents.get(JUDGE_AGENT_NAME)
    if not judge_config:
        raise ValueError(f"'{JUDGE_AGENT_NAME}'ì˜ ì„¤ì •ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    final_team = DebateTeam(
        discussion_id=discussion_id,
        judge=AgentDetail(**judge_config),
        jury=final_jury_details,
        reason=selected_jury.reason
    )

    print(f"--- [Orchestrator] 3ë‹¨ê³„: ë°°ì‹¬ì›ë‹¨ ì„ ì • ì™„ë£Œ ---")
    return final_team