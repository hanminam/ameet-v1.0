# src/app/services/discussion_flow.py
# ë¯¸ë˜ì— êµ¬í˜„ë  ë³µì¡í•œ í† ë¡  ë¡œì§ì„ ì„ì‹œë¡œ ëŒ€ì²´í•˜ëŠ” 'ê¸°ëŠ¥ì ì¸ ëª©ì—…(Functional Mock)' 

import asyncio
import json
from typing import List, Literal, Optional
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from app.tools.search import web_search_tool
from datetime import datetime

from pydantic import BaseModel, ValidationError

from app import db
from app.db import redis_client

from app.schemas.orchestration import DebateTeam
from app.models.discussion import AgentSettings, DiscussionLog
from app.services.utility_agents import run_snr_agent, run_verifier_agent
from app.core.config import logger

from app.schemas.orchestration import AgentDetail # AgentDetail ìŠ¤í‚¤ë§ˆ ì¶”ê°€
from app.schemas.discussion import VoteContent
from app.schemas.discussion import InteractionAnalysisResult
import re

# ì—ì´ì „íŠ¸ ë° ë„êµ¬ ì‹¤í–‰ì„ ìœ„í•œ LangChain ëª¨ë“ˆ ì„í¬íŠ¸
from langchain.agents import AgentExecutor, create_tool_calling_agent
from app.tools.search import available_tools

# ReAct íŒ¨í„´ì„ ì ìš©í•œ ê°•ë ¥í•œ ì‹œìŠ¤í…œ ë ˆë²¨ ë„êµ¬ ì‚¬ìš© ê·œì¹™ ì •ì˜
SYSTEM_TOOL_INSTRUCTION_BLOCK = """
---
### Tools Guide (VERY IMPORTANT)

You have access to a `web_search` tool. Follow this process:

1.  **THOUGHT:** Analyze the request. If you need up-to-date information (recent events, data, etc.), you MUST use the web_search tool.
2.  **ACTION:** Output a JSON object to call the tool.
3.  **EVALUATION (NEW STEP):** After receiving the search results from the Observation, you MUST critically evaluate them. Consider the source's credibility, check for biases, and see if multiple sources confirm the information. Do not blindly trust a single source.
4.  **FINAL ANSWER:** Based on your critical evaluation of the search results, formulate your comprehensive final answer in natural Korean.

**CRITICAL RULES:**
-   Your final answer MUST be a complete, natural language response.
-   Your final answer MUST NOT be a JSON object.
-   Do not mention your tool usage (e.g., "I searched for...") in your final answer. If you found conflicting information, you can state that "there are differing views on this topic."
---
"""

# ì…ì¥ ë³€í™” ë¶„ì„ ê²°ê³¼ Pydantic ëª¨ë¸
class StanceAnalysis(BaseModel):
    change: Literal['ìœ ì§€', 'ê°•í™”', 'ìˆ˜ì •', 'ì•½í™”']
    reason: str

# ê°œë³„ ì—ì´ì „íŠ¸ì˜ ì…ì¥ ë³€í™”ë¥¼ ë¶„ì„í•˜ëŠ” AI í˜¸ì¶œ í•¨ìˆ˜
async def _get_single_stance_change(
    agent_name: str, prev_statement: str, current_statement: str, discussion_id: str, turn_number: int
) -> dict:
    logger.info(f"--- [Stance Analysis] Agent: {agent_name}, Turn: {turn_number} ë¶„ì„ ì‹œì‘ ---")
    try:
        analyst_setting = await AgentSettings.find_one(
            AgentSettings.name == "Stance Analyst", AgentSettings.status == "active"
        )
        # 1. Stance Analyst ì—ì´ì „íŠ¸ë¥¼ DBì—ì„œ ì°¾ì•˜ëŠ”ì§€ í™•ì¸
        if not analyst_setting:
            # logger.warning("!!! [Stance Analysis] 'Stance Analyst' ì—ì´ì „íŠ¸ë¥¼ DBì—ì„œ ì°¾ì„ ìˆ˜ ì—†ê±°ë‚˜ 'active' ìƒíƒœê°€ ì•„ë‹™ë‹ˆë‹¤.")
            return {"agent_name": agent_name, "change": "ë¶„ì„ ë¶ˆê°€", "icon": "â“"}
        # logger.info("'Stance Analyst' ì—ì´ì „íŠ¸ ì„¤ì •ì„ ì„±ê³µì ìœ¼ë¡œ ì°¾ì•˜ìŠµë‹ˆë‹¤.")

        transcript_to_analyze = (
            f"ì—ì´ì „íŠ¸ ì´ë¦„: {agent_name}\n\n"
            f"ì´ì „ ë°œì–¸: \"{prev_statement}\"\n\n"
            f"í˜„ì¬ ë°œì–¸: \"{current_statement}\""
        )
        # 2. AIì—ê²Œ ì „ë‹¬ë  ìµœì¢… í”„ë¡¬í”„íŠ¸ ë‚´ìš©ì„ ë¡œê·¸ë¡œ ì¶œë ¥
        # logger.info(f"--- AIì—ê²Œ ì „ë‹¬ë  í”„ë¡¬í”„íŠ¸ ---\n{transcript_to_analyze}\n---------------------------")

        analyst_agent = ChatGoogleGenerativeAI(model=analyst_setting.config.model)
        structured_llm = analyst_agent.with_structured_output(StanceAnalysis)
        prompt = ChatPromptTemplate.from_messages([
            ("system", analyst_setting.config.prompt),
            ("human", "ë‹¤ìŒ í† ë¡  ëŒ€í™”ë¡ì„ ë¶„ì„í•˜ì„¸ìš”:\n\n{transcript}")
        ])
        chain = prompt | structured_llm
        
        analysis = await chain.ainvoke(
            {"transcript": transcript_to_analyze},
            config={"tags": [f"discussion_id:{discussion_id}", f"turn:{turn_number}", "task:stance_analysis"]}
        )
        
        # 3. AIì˜ ì‘ë‹µì´ ì„±ê³µì ìœ¼ë¡œ íŒŒì‹±ë˜ì—ˆëŠ”ì§€ í™•ì¸
        # logger.info(f"ì„±ê³µì ìœ¼ë¡œ AI ì‘ë‹µì„ íŒŒì‹±í–ˆìŠµë‹ˆë‹¤: {analysis}")
        
        icon_map = {"ìœ ì§€": "ğŸ˜", "ê°•í™”": "ğŸ”¼", "ìˆ˜ì •": "ğŸ”„", "ì•½í™”": "ğŸ”½"}
        return {"agent_name": agent_name, "change": analysis.change, "icon": icon_map.get(analysis.change, "â“")}
    
    except Exception as e:
        # 4. ì˜¤ë¥˜ ë°œìƒ ì‹œ, ì •í™•í•œ ì˜¤ë¥˜ ë©”ì‹œì§€ë¥¼ ë¡œê·¸ë¡œ ì¶œë ¥
        logger.error(f"!!! [Stance Analysis] ì—ëŸ¬ ë°œìƒ: Agent '{agent_name}'ì˜ ì…ì¥ ë¶„ì„ ì¤‘ ì‹¤íŒ¨. ì—ëŸ¬: {e}", exc_info=True)
        return {"agent_name": agent_name, "change": "ë¶„ì„ ë¶ˆê°€", "icon": "â“"}

# ëª¨ë“  ì°¸ì—¬ìì˜ ì…ì¥ ë³€í™”ë¥¼ ë³‘ë ¬ë¡œ ë¶„ì„í•˜ëŠ” ë©”ì¸ í•¨ìˆ˜
async def _analyze_stance_changes(transcript: List[dict], jury_members: List[dict], discussion_id: str, turn_number: int) -> List[dict]:
    num_jury = len(jury_members)
    # logger.info(f"--- [Stance Analysis] ì…ì¥ ë³€í™” ë¶„ì„ ì‹œì‘. Turn: {turn_number}, Transcript Lenth: {len(transcript)}, Jury Members: {num_jury} ---")
    
    # 1. ë¶„ì„ì„ ì‹¤í–‰í•  ì¡°ê±´ì´ ë§ëŠ”ì§€ í™•ì¸
    if turn_number < 1 or len(transcript) < num_jury * 2:
        # logger.warning(f"ë¶„ì„ ì¡°ê±´ ë¯¸ì¶©ì¡±ìœ¼ë¡œ ì…ì¥ ë³€í™” ë¶„ì„ì„ ê±´ë„ˆëœë‹ˆë‹¤. (Turn: {turn_number}, Transcript Lenth: {len(transcript)})")
        return []

    current_round_map = {turn['agent_name']: turn['message'] for turn in transcript[-num_jury:]}
    prev_round_map = {turn['agent_name']: turn['message'] for turn in transcript[-num_jury*2:-num_jury]}

    # 2. ì´ì „ ë¼ìš´ë“œì™€ í˜„ì¬ ë¼ìš´ë“œì˜ ë°œì–¸ì´ ì˜¬ë°”ë¥´ê²Œ ì¶”ì¶œë˜ì—ˆëŠ”ì§€ í™•ì¸
    # logger.info(f"ì´ì „ ë¼ìš´ë“œ ë°œì–¸ì: {list(prev_round_map.keys())}")
    # logger.info(f"í˜„ì¬ ë¼ìš´ë“œ ë°œì–¸ì: {list(current_round_map.keys())}")

    tasks = []
    for agent in jury_members:
        agent_name = agent['name']
        if agent_name in prev_round_map and agent_name in current_round_map:
            task = _get_single_stance_change(
                agent_name, 
                prev_round_map[agent_name], 
                current_round_map[agent_name], 
                discussion_id, 
                turn_number
            )
            tasks.append(task)
        else:
            # 3. íŠ¹ì • ì—ì´ì „íŠ¸ì˜ ë°œì–¸ì´ ëˆ„ë½ë˜ì—ˆëŠ”ì§€ í™•ì¸
            logger.warning(f"!!! '{agent_name}' ì—ì´ì „íŠ¸ì˜ ì´ì „ ë˜ëŠ” í˜„ì¬ ë°œì–¸ì´ ì—†ì–´ ë¶„ì„ì—ì„œ ì œì™¸ë©ë‹ˆë‹¤.")
    
    if not tasks:
        # logger.warning("ë¶„ì„í•  ì—ì´ì „íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return []
        
    results = await asyncio.gather(*tasks)
    # logger.info(f"--- [Stance Analysis] ì…ì¥ ë³€í™” ë¶„ì„ ì™„ë£Œ. ê²°ê³¼ ìˆ˜: {len(results)} ---")
    return results

# ë¼ìš´ë“œ ìš”ì•½ ë¶„ì„ì„ ìœ„í•œ Pydantic ëª¨ë¸
class CriticalUtterance(BaseModel):
    agent_name: str
    message: str

async def _get_round_summary(transcript_str: str, discussion_id: str, turn_number: int) -> dict:
    """ë¼ìš´ë“œ ëŒ€í™”ë¡ì„ ë¶„ì„í•˜ì—¬ ê²°ì •ì  ë°œì–¸ì„ ì„ ì •í•˜ëŠ” AI ì—ì´ì „íŠ¸ë¥¼ í˜¸ì¶œí•©ë‹ˆë‹¤."""
    try:
        # DBì—ì„œ Round Analyst ì—ì´ì „íŠ¸ ì„¤ì •ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.
        analyst_setting = await AgentSettings.find_one(
            AgentSettings.name == "Round Analyst", AgentSettings.status == "active"
        )
        if not analyst_setting: return None

        analyst_agent = ChatGoogleGenerativeAI(model=analyst_setting.config.model)
        structured_llm = analyst_agent.with_structured_output(CriticalUtterance)
        
        prompt = ChatPromptTemplate.from_messages([
            ("system", analyst_setting.config.prompt),
            ("human", "Analyze the following transcript:\n\n{transcript}")
        ])
        
        chain = prompt | structured_llm
        summary = await chain.ainvoke(
            {"transcript": transcript_str},
            config={"tags": [f"discussion_id:{discussion_id}", f"turn:{turn_number}", "task:summarize"]}
        )
        return summary.dict()
    except Exception as e:
        logger.error(f"Error getting round summary: {e}")
        return None

async def _run_single_agent_turn(
    agent_config: dict,
    topic: str,
    history: str,
    evidence: str,
    special_directive: str,
    discussion_id: str,
    turn_count: int
) -> str:
    """ë‹¨ì¼ ì—ì´ì „íŠ¸ì˜ ë°œì–¸(turn)ì„ ìƒì„±í•©ë‹ˆë‹¤. ëª¨ë“  ì—ì´ì „íŠ¸ëŠ” í•„ìš” ì‹œ ì›¹ ê²€ìƒ‰ ë„êµ¬ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."""
    agent_name = agent_config.get("name", "Unknown Agent")
    logger.info(f"--- [Flow] Running turn for agent: {agent_name} (Discussion: {discussion_id}, Turn: {turn_count}) ---")

    try:
        llm = ChatGoogleGenerativeAI(
            model=agent_config.get("model", "gemini-1.5-flash"),
            temperature=agent_config.get("temperature", 0.2)
        )

        human_instruction = (
            "ì§€ê¸ˆì€ 'ëª¨ë‘ ë³€ë¡ ' ì‹œê°„ì…ë‹ˆë‹¤. ìœ„ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ë‹¹ì‹ ì˜ ì´ˆê¸° ì…ì¥ì„ ìµœì†Œ 100ìì—ì„œ ìµœëŒ€ 500ì ì´ë‚´ë¡œ ì„¤ëª…í•´ì£¼ì„¸ìš”."
            if turn_count == 0 else
            f"ì§€ê¸ˆì€ '{turn_count + 1}ì°¨ í† ë¡ ' ì‹œê°„ì…ë‹ˆë‹¤. ì´ì „ì˜ ì—ì´ì „íŠ¸ë“¤ì˜ ì˜ê²¬ì„ ê³ ë ¤í•˜ì—¬ ë‹¤ë¥¸ ì—ì´ì „íŠ¸ì˜ ì£¼ì¥ì„ ë°˜ë°•í•˜ê±°ë‚˜ ë‹¤ë¥¸ ì—ì´ì „íŠ¸ì˜ ì˜ê²¬ì— ì ê·¹ ë™ì¡°í•˜ê±°ë‚˜ ì•„ë‹ˆë©´ ë‹¤ë¥¸ ì—ì´ì „íŠ¸ì˜ ì˜ê²¬ì„ ìˆ˜ë ´í•˜ì—¬ ì˜ê²¬ì„ ìˆ˜ì •í•œ ë‹¹ì‹ ì˜ ì˜ê²¬ì„ ì£¼ì¥í•©ë‹ˆë‹¤. ë‹¤ë¥¸ ì—ì´ì „íŠ¸ì˜ ë…¼ë¦¬ì  ëª¨ìˆœì´ë‚˜ ì‚¬ì‹¤ì— ìœ„ë°°ë˜ëŠ” ì£¼ì¥ì´ ìˆë‹¤ê³  ìƒê°í•œë‹¤ë©´ ì ê·¹ì ìœ¼ë¡œ ë°˜ë°•í•˜ì‹­ì‹œìš”. ë‹¤ë¥¸ ì—ì´ì „íŠ¸ê°€ ìƒê°í•˜ì§€ ëª»í•˜ëŠ” ìƒˆë¡œìš´ ì•„ì´ë””ì–´, ë…ì°½ì ì¸ ì£¼ì¥, ê·¸ë¦¬ê³  í† ë¡ ì˜ ì£¼ì œë¥¼ ì‹¬í™”í•  ìˆ˜ ìˆë‹¤ê³  ìƒê°ë˜ëŠ” ë‚´ìš©ì„ ì ê·¹ì ìœ¼ë¡œ ì£¼ì¥í•©ë‹ˆë‹¤. ë˜í•œ, ì´ì „ í† ë¡  ì°¨ìˆ˜ì—ì„œ ì£¼ì¥í•œ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ìì‹ ì˜ ì£¼ì¥ì¤‘ì— ë³´ë‹¤ êµ¬ì²´ì ì¸ ëŒ€ì•ˆ, êµ¬ì²´ì ì¸ ë°©ì•ˆë“±ìœ¼ë¡œ ìì‹ ì˜ ì£¼ì¥ì„ ì‹¬í™” ë°œì „í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤. í† ë¡ ì˜ ì°¨ìˆ˜ê°€ ë†’ì•„ì§ˆìˆ˜ë¡ ì´ì „ ìì‹ ì˜ ì£¼ì¥ì„ ë™ì–´ë°˜ë³µí•˜ê¸° ë³´ë‹¨ ë³´ë‹¤ êµ¬ì²´ì ì¸ ëŒ€ì•ˆì„ ì£¼ì¥í•©ë‹ˆë‹¤. ì£¼ì¥ì€ ìµœì†Œ 200ì ìµœëŒ€ 500ì ì´ë‚´ë¡œ ì¶”ê°€í•´ì£¼ì„¸ìš”."
        )

        final_human_prompt = (
            f"ë‹¹ì‹ ì€ ë‹¤ìŒ í† ë¡ ì— ì°¸ì—¬í•˜ëŠ” AI ì—ì´ì „íŠ¸ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ ì°¸ê³  ìë£Œì™€ í† ë¡  ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ë‹¹ì‹ ì˜ ì„ë¬´ë¥¼ ìˆ˜í–‰í•˜ì„¸ìš”.\n\n"
            f"### ì „ì²´ í† ë¡  ì£¼ì œ: {topic}\n\n"
            f"### ì°¸ê³  ìë£Œ (ì´ˆê¸° ë¶„ì„ ì •ë³´)\n{evidence}\n"
            f"### ì§€ê¸ˆê¹Œì§€ì˜ í† ë¡  ë‚´ìš©:\n{history if history else 'ì•„ì§ í† ë¡  ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤.'}\n\n"
            f"{special_directive}\n"
            f"### ë‹¹ì‹ ì˜ ì„ë¬´\n{human_instruction}"
        )

        logger.info(f"--- [Flow] Agent '{agent_name}' will now decide on tool usage autonomously. ---")
        
        original_system_prompt = agent_config.get("prompt", "You are a helpful assistant.")
        tool_system_prompt = SYSTEM_TOOL_INSTRUCTION_BLOCK + "\n\n" + original_system_prompt

        prompt = ChatPromptTemplate.from_messages([
            ("system", tool_system_prompt),
            ("human", "{input}"),
            MessagesPlaceholder(variable_name="agent_scratchpad"),
        ])
        
        tools = [web_search_tool]
        agent = create_tool_calling_agent(llm, tools, prompt)
        agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)
        
        response = await agent_executor.ainvoke(
            {"input": final_human_prompt},
            config={"tags": [f"discussion_id:{discussion_id}", f"agent_name:{agent_name}", f"turn:{turn_count}"]}
        )
        return response.get("output", "ì˜¤ë¥˜: ì‘ë‹µì„ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

    except Exception as e:
        logger.error(f"--- [Flow Error] Agent '{agent_name}' turn failed: {e} ---", exc_info=True)
        return f"({agent_name} ë°œì–¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ)"
    
# í† ë¡  íë¦„ë„ ë¶„ì„ì„ ìœ„í•œ í—¬í¼ í•¨ìˆ˜
async def _analyze_flow_data(transcript: List[dict], jury_members: List[dict], discussion_id: str, turn_number: int) -> dict:
    """
    LLM ê¸°ë°˜ 'Interaction Analyst'ë¥¼ ì‚¬ìš©í•˜ì—¬ í† ë¡ ì˜ ìƒí˜¸ì‘ìš©ì„ ë¶„ì„í•©ë‹ˆë‹¤.
    """
    logger.info(f"--- [Flow Analysis] LLM-based interaction analysis started for Turn: {turn_number} ---")
    
    # 1. í˜„ì¬ ë¼ìš´ë“œì˜ ëŒ€í™”ë§Œ ë¬¸ìì—´ë¡œ ì¶”ì¶œ
    current_round_transcript_str = "\n\n".join(
        [f"{turn['agent_name']}: {turn['message']}" for turn in transcript[-len(jury_members):]]
    )

    try:
        # 2. DBì—ì„œ Interaction Analyst ì—ì´ì „íŠ¸ ì„¤ì •ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.
        analyst_setting = await AgentSettings.find_one(
            AgentSettings.name == "Interaction Analyst", AgentSettings.status == "active"
        )
        if not analyst_setting:
            logger.error("!!! [Flow Analysis] 'Interaction Analyst' ì—ì´ì „íŠ¸ë¥¼ DBì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return {"interactions": []}

        # 3. LLM ë° ì²´ì¸ êµ¬ì„±
        llm = ChatGoogleGenerativeAI(model=analyst_setting.config.model, temperature=analyst_setting.config.temperature)
        structured_llm = llm.with_structured_output(InteractionAnalysisResult)
        
        prompt = ChatPromptTemplate.from_messages([
            ("system", analyst_setting.config.prompt),
            ("human", "Please analyze the following transcript:\n\n{transcript}")
        ])
        chain = prompt | structured_llm

        # 4. LLM í˜¸ì¶œí•˜ì—¬ ë¶„ì„ ì‹¤í–‰
        analysis_result = await chain.ainvoke(
            {"transcript": current_round_transcript_str},
            config={"tags": [f"discussion_id:{discussion_id}", f"turn:{turn_number}", "task:flow_analysis"]}
        )

        # 5. Pydantic ëª¨ë¸ì„ í”„ë¡ íŠ¸ì—”ë“œê°€ ì‚¬ìš©í•˜ëŠ” ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
        # Pydantic ëª¨ë¸ì˜ alias('from', 'to', 'type')ë¥¼ ì›ë˜ í•„ë“œëª…ìœ¼ë¡œ ë³€í™˜
        interactions_list = [
            {
                "from": interaction.from_agent,
                "to": interaction.to_agent,
                "type": interaction.interaction_type
            }
            for interaction in analysis_result.interactions
        ]
        
        logger.info(f"--- [Flow Analysis] Analysis complete. Found {len(interactions_list)} interactions. ---")
        return {"interactions": interactions_list}

    except Exception as e:
        logger.error(f"!!! [Flow Analysis] Error during interaction analysis: {e}", exc_info=True)
        return {"interactions": []}

# íˆ¬í‘œ ìƒì„±ì„ ìœ„í•œ ë³„ë„ì˜ í—¬í¼ í•¨ìˆ˜
async def _generate_vote_options(transcript_str: str, discussion_id: str, turn_number: int, vote_history: List[str], topic: str) -> Optional[dict]:
    """
    ëŒ€í™”ë¡ê³¼ í† ë¡  ì£¼ì œë¥¼ ë¶„ì„í•˜ì—¬ ìƒˆë¡œìš´ íˆ¬í‘œ ì£¼ì œì™€ ì„ íƒì§€ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    - TypeError ë°©ì§€ë¥¼ ìœ„í•´ topic ì¸ìë¥¼ ë°›ìŠµë‹ˆë‹¤.
    - KeyError ë°©ì§€ë¥¼ ìœ„í•´ ëŒ€í™”ë¡ì˜ ì¤‘ê´„í˜¸ë¥¼ ì´ìŠ¤ì¼€ì´í”„ ì²˜ë¦¬í•©ë‹ˆë‹¤.
    - JSON íŒŒì‹± ì˜¤ë¥˜ ë°©ì§€ë¥¼ ìœ„í•´ ì•ˆì •ì ì¸ 2ë‹¨ê³„ íŒŒì‹± ë¡œì§ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.
    - í•œê¸€ ì˜¤íƒ€ ë°©ì§€ë¥¼ ìœ„í•´ 'í•µì‹¬ ìš©ì–´' ê°€ì´ë“œë¼ì¸ì„ ë™ì ìœ¼ë¡œ ìƒì„±í•©ë‹ˆë‹¤.
    """
    logger.info(f"--- [Vote Generation] Turn: {turn_number} íˆ¬í‘œ ìƒì„± ì‹œì‘ ---")
    raw_response = ""
    json_str = ""
    try:
        vote_caster_setting = await AgentSettings.find_one(
            AgentSettings.name == "Vote Caster", AgentSettings.status == "active"
        )
        if not vote_caster_setting:
            logger.error("!!! [Vote Generation] 'Vote Caster' ì—ì´ì „íŠ¸ë¥¼ DBì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return None

        # ì´ì „ íˆ¬í‘œ ê¸°ë¡ ì„¹ì…˜ ìƒì„±
        history_prompt_section = "ì•„ì§ ì‚¬ìš©ìì˜ ì´ì „ íˆ¬í‘œ ê¸°ë¡ì´ ì—†ìŠµë‹ˆë‹¤."
        if vote_history:
            history_items = "\n".join([f"- '{item}'" for item in vote_history])
            history_prompt_section = f"### ì´ì „ íˆ¬í‘œì—ì„œ ì‚¬ìš©ìê°€ ì„ íƒí•œ í•­ëª©ë“¤:\n{history_items}"

        # 2. í† ë¡  ì£¼ì œë¥¼ ë°”íƒ•ìœ¼ë¡œ 'í•µì‹¬ ìš©ì–´' ê°€ì´ë“œë¼ì¸ì„ ë™ì ìœ¼ë¡œ ìƒì„± (í•µì‹¬ ìˆ˜ì •!)
        key_terms_guide = f"### Key Terms (Use these exact Korean spellings):\n- '{topic}'"

        # ëŒ€í™”ë¡ì— í¬í•¨ë  ìˆ˜ ìˆëŠ” ì¤‘ê´„í˜¸ë¥¼ ì´ìŠ¤ì¼€ì´í”„ ì²˜ë¦¬í•˜ì—¬ KeyErrorë¥¼ ì›ì²œ ë°©ì§€
        safe_transcript_str = transcript_str.replace('{', '{{').replace('}', '}}')

        # ìµœì¢… í”„ë¡¬í”„íŠ¸ ì¡°ë¦½
        final_human_prompt = (
            f"{key_terms_guide}\n\n" # <--- í•œ ì¤„ ë„ì›Œì„œ ê°€ë…ì„± í™•ë³´
            f"{history_prompt_section}\n\n"
            f"### í˜„ì¬ ë¼ìš´ë“œê¹Œì§€ì˜ ì „ì²´ í† ë¡  ëŒ€í™”ë¡:\n{safe_transcript_str}"
        )

        # LLM í˜¸ì¶œ
        vote_caster_agent = ChatGoogleGenerativeAI(
            model=vote_caster_setting.config.model,
            temperature=vote_caster_setting.config.temperature,
            model_kwargs={"response_mime_type": "application/json"}
        )
        
        prompt = ChatPromptTemplate.from_messages([
            ("system", vote_caster_setting.config.prompt),
            ("human", final_human_prompt)
        ])
        
        chain = prompt | vote_caster_agent
        response = await chain.ainvoke(
            {},
            config={"tags": [f"discussion_id:{discussion_id}", f"turn:{turn_number}", "task:generate_vote"]}
        )

        raw_response = response.content
        
        # ì•ˆì •ì ì¸ 2ë‹¨ê³„ íŒŒì‹± ë¡œì§
        # 1. LLM ì‘ë‹µì—ì„œ ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡ ì œê±°
        match = re.search(r"```(json)?\s*({.*?})\s*```", raw_response, re.DOTALL)
        json_str = match.group(2) if match else raw_response

        # 2. Python ê¸°ë³¸ json ë¼ì´ë¸ŒëŸ¬ë¦¬ë¡œ ë¨¼ì € íŒŒì‹±
        parsed_json = json.loads(json_str)
        
        # 3. íŒŒì‹±ëœ ë”•ì…”ë„ˆë¦¬ë¥¼ Pydanticìœ¼ë¡œ ê²€ì¦
        vote_content = VoteContent.model_validate(parsed_json)
        
        logger.info(f"--- [Vote Generation] íˆ¬í‘œ ìƒì„± ë° íŒŒì‹± ì™„ë£Œ: {vote_content.topic} ---")
        return vote_content.model_dump()
        
    except (ValidationError, json.JSONDecodeError) as e:
        logger.error(f"!!! [Vote Generation] JSON íŒŒì‹±/ê²€ì¦ ì˜¤ë¥˜. ì˜¤ë¥˜: {e}\nì›ë³¸ ì‘ë‹µ: {raw_response}", exc_info=True)
        # íŒŒì‹± ì‹¤íŒ¨ ì‹œ, ì‚¬ìš©ìì—ê²Œ ë‹¤ìŒ ë¼ìš´ë“œë¡œ ë„˜ì–´ê°ˆ ìˆ˜ ìˆëŠ” ê¸°ë³¸ ì˜µì…˜ ì œê³µ
        return {
            "topic": "ë‹¤ìŒìœ¼ë¡œ ì–´ë–¤ í† ë¡ ì„ ì§„í–‰í• ê¹Œìš”?",
            "options": ["ê°€ì¥ ì˜ê²¬ì´ ì—‡ê°ˆë¦¬ëŠ” ìŸì ì— ëŒ€í•´ ì¶”ê°€ ë°˜ë¡ ", "ìƒˆë¡œìš´ ê´€ì ì˜ ì „ë¬¸ê°€ ì¶”ê°€ íˆ¬ì… ìš”ì²­", "í˜„ì¬ê¹Œì§€ ë‚´ìš© ì¤‘ê°„ ìš”ì•½"]
        }
    except Exception as e:
        logger.error(f"!!! [Vote Generation] íˆ¬í‘œ ìƒì„± ì¤‘ ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜ ë°œìƒ: {e}", exc_info=True)
        return None
    
async def execute_turn(discussion_log: DiscussionLog, user_vote: Optional[str] = None):
    """
    ë°±ê·¸ë¼ìš´ë“œì—ì„œ ë‹¨ì¼ í† ë¡  í„´ì„ ì‹¤í–‰í•˜ê³ , ê²°ê³¼ë¥¼ DBì— ê¸°ë¡í•©ë‹ˆë‹¤.
    ì‚¬ìš©ìì˜ íˆ¬í‘œ ê¸°ë¡ì€ Redisë¥¼ í†µí•´ ì„¸ì…˜ìœ¼ë¡œ ê´€ë¦¬í•©ë‹ˆë‹¤.
    """
    logger.info(f"--- [BG Task] Executing turn for Discussion ID: {discussion_log.discussion_id} ---")

    # --- ì‚¬íšŒì ì•ˆë‚´ ë©”ì‹œì§€ ì¶”ê°€ ---
    # ì‚¬ìš©ì íˆ¬í‘œê°€ ìˆê³ , ì²« í„´(ëª¨ë‘ ë³€ë¡ )ì´ ì•„ë‹ ë•Œ ì‚¬íšŒì ì•ˆë‚´ ë©”ì‹œì§€ë¥¼ ë¨¼ì € ì¶”ê°€í•©ë‹ˆë‹¤.
    if user_vote and discussion_log.turn_number > 0:
        round_name = "ëª¨ë‘ ë³€ë¡ " if discussion_log.turn_number == 1 else f"{discussion_log.turn_number - 1}ì°¨ í† ë¡ "
        
        # 'ì„(ë¥¼)' ì¡°ì‚¬ ì²˜ë¦¬
        last_char = user_vote[-1]
        postposition = "ì„" if (ord(last_char) - 0xAC00) % 28 > 0 else "ë¥¼"

        moderator_message = (
            f"{round_name}ì´ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. "
            f"ì‚¬ìš©ìëŠ” '{discussion_log.current_vote['topic']}' íˆ¬í‘œì— "
            f"'{user_vote}'{postposition} ì„ íƒí•˜ì˜€ìŠµë‹ˆë‹¤. ë‹¤ìŒ í† ë¡ ì„ ì‹œì‘í•©ë‹ˆë‹¤."
        )
        moderator_turn_data = {
            "agent_name": "ì‚¬íšŒì", 
            "message": moderator_message, 
            "timestamp": datetime.utcnow()
        }
        discussion_log.transcript.append(moderator_turn_data)
    
    redis_key = f"vote_history:{discussion_log.discussion_id}"
    vote_history = []
    try:
        history_json = await db.redis_client.get(redis_key)
        if history_json:
            vote_history = json.loads(history_json)
    except Exception as e:
        logger.error(f"!!! [Redis Error] Redisì—ì„œ íˆ¬í‘œ ê¸°ë¡ì„ ê°€ì ¸ì˜¤ëŠ” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}", exc_info=True)

    if user_vote:
        vote_history.append(user_vote)
        try:
            await db.redis_client.set(redis_key, json.dumps(vote_history), ex=86400)
            logger.info(f"--- [BG Task] ì‚¬ìš©ì íˆ¬í‘œ '{user_vote}'ë¥¼ Redisì— ê¸°ë¡í–ˆìŠµë‹ˆë‹¤. í˜„ì¬ ê¸°ë¡: {vote_history} ---")
        except Exception as e:
            logger.error(f"!!! [Redis Error] Redisì— íˆ¬í‘œ ê¸°ë¡ì„ ì €ì¥í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}", exc_info=True)

    current_turn = discussion_log.turn_number
    history_str = "\n\n".join([f"{t['agent_name']}: {t['message']}" for t in discussion_log.transcript])

    # DBì— ì €ì¥ëœ ì¦ê±° ìë£Œë¥¼ ë¶ˆëŸ¬ì™€ í”„ë¡¬í”„íŠ¸ì— í¬í•¨í•  ë¬¸ìì—´ë¡œ ë§Œë“­ë‹ˆë‹¤.
    evidence_str = ""
    if discussion_log.evidence_briefing:
        web_evidence = "\n".join([f"- {item['summary']} (ì¶œì²˜: {item['source']})" for item in discussion_log.evidence_briefing.get('web_evidence', [])])
        file_evidence = "\n".join([f"- {item['summary']} (ì¶œì²˜: {item['source']})" for item in discussion_log.evidence_briefing.get('file_evidence', [])])
        
        evidence_str += "--- [ì°¸ê³  ìë£Œ: ì›¹ ê²€ìƒ‰ ê²°ê³¼ ìš”ì•½] ---\n"
        evidence_str += web_evidence + "\n" if web_evidence else "ê´€ë ¨ ì›¹ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.\n"
        evidence_str += "--- [ì°¸ê³  ìë£Œ: ì œì¶œ íŒŒì¼ ìš”ì•½] ---\n"
        evidence_str += file_evidence + "\n" if file_evidence else "ì œì¶œëœ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.\n"


    special_directive = ""
    if user_vote:
        special_directive = (
            f"\n\n--- íŠ¹ë³„ ì§€ì‹œë¬¸ ---\n"
            f"ì‚¬ìš©ìëŠ” ì§ì „ ë¼ìš´ë“œì—ì„œ '{user_vote}' ê´€ì ì— ëŒ€í•œ ë‹¹ì‹ ì˜ ì˜ê²¬ì„ ë“£ê³ ì‹¶ì–´í•©ë‹ˆë‹¤."
            f"ì´ ê´€ì ì„ í¬í•¨í•˜ì—¬ ë‹¹ì‹ ì˜ ì£¼ì¥ì„ ê°•í™” ë˜ëŠ” ìˆ˜ì •í•˜ê±°ë‚˜ ë‹¤ë¥¸ ì—ì´ì „íŠ¸ë“¤ì˜ ì£¼ì¥ì„ ë°˜ë°•í•˜ì‹­ì‹œì˜¤."
            f"ê·¸ëŸ¬ë‚˜ ì´ ê´€ì ì´ ë‹¹ì‹ ì˜ ìƒê°ì— ì¤‘ìš”í•˜ì§€ ì•Šë‹¤ë©´ ì´ í† ë¡ ì´ ì–´ë–¤ ë°©í–¥ì— ì¤‘ì ì„ ë‘ì–´ì•¼ í•˜ëŠ”ì§€ ì•ìœ¼ë¡œ ì–´ë–¤ ë…¼ì˜ë¥¼ ì‹¬í™” ë°œì „ì‹œì¼œì•¼ í•˜ëŠ”ì§€ ì˜¤íˆë ¤ ì ê·¹ì ìœ¼ë¡œ ë‹¹ì‹ ì˜ ì£¼ì¥ì„ í¼ì¹ ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤."
            f"\n-------------------\n"
        )

    excluded_roles = ["ì¬íŒê´€", "ì‚¬íšŒì"]
    jury_members = [p for p in discussion_log.participants if p.get('name') not in excluded_roles]

    # --- ì—ì´ì „íŠ¸ ë°œì–¸ì„ ìˆœì°¨ ì‹¤í–‰ì—ì„œ ë™ì‹œ ì‹¤í–‰ìœ¼ë¡œ ë³€ê²½ ---

    # 1. ëª¨ë“  ì—ì´ì „íŠ¸ì˜ ë¹„ë™ê¸° ì‘ì—…ì„ ë‹´ì„ ë¦¬ìŠ¤íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    tasks = []
    for agent_config in jury_members:
        # 2. awaitë¡œ ì¦‰ì‹œ ì‹¤í–‰í•˜ëŠ” ëŒ€ì‹ , ì‹¤í–‰í•  ì‘ì—…(ì½”ë£¨í‹´)ì„ ë§Œë“¤ì–´ tasks ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€í•©ë‹ˆë‹¤.
        task = _run_single_agent_turn(
            agent_config, 
            discussion_log.topic, 
            history_str, 
            evidence_str,  # ì¦ê±° ìë£Œ ì „ë‹¬
            special_directive,
            discussion_log.discussion_id,
            current_turn
        )
        tasks.append(task)

    # 3. asyncio.gatherë¥¼ ì‚¬ìš©í•´ ëª¨ë“  ì‘ì—…ì„ ë™ì‹œì— ì‹¤í–‰í•˜ê³ , ëª¨ë“  ê²°ê³¼ê°€ ë„ì°©í•  ë•Œê¹Œì§€ ê¸°ë‹¤ë¦½ë‹ˆë‹¤.
    logger.info(f"--- [BG Task] {len(tasks)}ëª…ì˜ ì—ì´ì „íŠ¸ ë°œì–¸ì„ ë™ì‹œì— ìƒì„± ì‹œì‘... (ID: {discussion_log.discussion_id})")
    messages = await asyncio.gather(*tasks)
    logger.info(f"--- [BG Task] ëª¨ë“  ì—ì´ì „íŠ¸ ë°œì–¸ ìƒì„± ì™„ë£Œ. (ID: {discussion_log.discussion_id})")

    # 4. ì´ì œ ëª¨ë“  ë‹µë³€ì´ ë„ì°©í–ˆìœ¼ë¯€ë¡œ, ê²°ê³¼ë¥¼ ìˆœì„œëŒ€ë¡œ transcriptì— ì¶”ê°€í•©ë‹ˆë‹¤.
    for i, message in enumerate(messages):
        agent_name = jury_members[i]['name']
        
        # 1. ì „ë¬¸ê°€ì˜ ë©”ì¸ ë°œì–¸ì„ ì¶”ê°€í•©ë‹ˆë‹¤.
        main_turn_data = {"agent_name": agent_name, "message": message, "timestamp": datetime.utcnow()}
        discussion_log.transcript.append(main_turn_data)

        # 2. ë©”ì¸ ë°œì–¸ì— ëŒ€í•´ Staff ì—ì´ì „íŠ¸ë“¤ì„ ë™ê¸°ì ìœ¼ë¡œ ì‹¤í–‰í•©ë‹ˆë‹¤.
        # (asyncio.to_threadë¥¼ ì‚¬ìš©í•´ non-blocking ë°©ì‹ìœ¼ë¡œ í˜¸ì¶œ)
        snr_result = await asyncio.to_thread(run_snr_agent, message)
        if snr_result:
            snr_turn_data = {
                "agent_name": "SNR ì „ë¬¸ê°€", 
                "message": json.dumps(snr_result, ensure_ascii=False), # ê²°ê³¼ë¥¼ JSON ë¬¸ìì—´ë¡œ ì €ì¥
                "timestamp": datetime.utcnow()
            }
            discussion_log.transcript.append(snr_turn_data)

        verifier_result = await asyncio.to_thread(run_verifier_agent, message)
        if verifier_result:
            verifier_turn_data = {
                "agent_name": "ì •ë³´ ê²€ì¦ë¶€", 
                "message": json.dumps(verifier_result, ensure_ascii=False), # ê²°ê³¼ë¥¼ JSON ë¬¸ìì—´ë¡œ ì €ì¥
                "timestamp": datetime.utcnow()
            }
            discussion_log.transcript.append(verifier_turn_data)

    # --- ë¼ìš´ë“œ ì¢…ë£Œ êµ¬ë¶„ì„  ì¶”ê°€] ---
    round_name_for_separator = "ëª¨ë‘ ë³€ë¡ " if discussion_log.turn_number == 0 else f"{discussion_log.turn_number}ì°¨ í† ë¡ "
    separator_message = f"---------- {round_name_for_separator} ì¢…ë£Œ ----------"
    separator_turn_data = {
        "agent_name": "êµ¬ë¶„ì„ ", 
        "message": separator_message, 
        "timestamp": datetime.utcnow()
    }
    discussion_log.transcript.append(separator_turn_data)
    
    logger.info(f"--- [BG Task] ë¼ìš´ë“œ {current_turn} ì™„ë£Œ. ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤... (ID: {discussion_log.discussion_id})")
    
    # ë¶„ì„ì— í•„ìš”í•œ ìµœì‹  ëŒ€í™”ë¡ ë¬¸ìì—´ ìƒì„± (ì´ë²ˆ ë¼ìš´ë“œ ë°œì–¸ë§Œ)
    final_transcript_str = "\n\n".join([f"{t['agent_name']}: {t['message']}" for t in discussion_log.transcript[-len(jury_members):]])
    
    analysis_tasks = {
        "round_summary": _get_round_summary(final_transcript_str, discussion_log.discussion_id, discussion_log.turn_number),
        "stance_changes": _analyze_stance_changes(discussion_log.transcript, jury_members, discussion_log.discussion_id, discussion_log.turn_number),
        "flow_data": asyncio.to_thread(_analyze_flow_data, discussion_log.transcript, jury_members)
    }
    
    analysis_results = await asyncio.gather(*analysis_tasks.values())
    analysis_map = dict(zip(analysis_tasks.keys(), analysis_results))

    discussion_log.round_summary = {
        "critical_utterance": analysis_map.get("round_summary"),
        "stance_changes": analysis_map.get("stance_changes")
    }
    discussion_log.flow_data = analysis_map.get("flow_data")

    logger.info(f"--- [BG Task] ë¶„ì„ ì™„ë£Œ. ê²°ê³¼ë¥¼ DBì— ì €ì¥í•©ë‹ˆë‹¤. (ID: {discussion_log.discussion_id})")
    
    # ë‹¤ìŒ ë¼ìš´ë“œë¥¼ ìœ„í•œ íˆ¬í‘œ ìƒì„±
    full_history_str = "\n\n".join([f"{t['agent_name']}: {t['message']}" for t in discussion_log.transcript])
    discussion_log.current_vote = await _generate_vote_options(
        full_history_str, 
        discussion_log.discussion_id, 
        discussion_log.turn_number,
        vote_history,
        discussion_log.topic
    )
    
    discussion_log.status = "waiting_for_vote"
    discussion_log.turn_number += 1
    
    await discussion_log.save()
    
    logger.info(f"--- [BG Task] Turn completed for {discussion_log.discussion_id}. New status: '{discussion_log.status}' ---")