# src/app/services/discussion_flow.py
# ë¯¸ë˜ì— êµ¬í˜„ë  ë³µì¡í•œ í† ë¡  ë¡œì§ì„ ì„ì‹œë¡œ ëŒ€ì²´í•˜ëŠ” 'ê¸°ëŠ¥ì ì¸ ëª©ì—…(Functional Mock)' 

import asyncio
import json
from typing import List, Literal, Optional
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from app.tools.search import web_search_tool
from datetime import datetime

from pydantic import BaseModel, ValidationError

from app import db
from app.db import redis_client

from app.schemas.orchestration import DebateTeam
from app.models.discussion import AgentSettings, DiscussionLog
from app.core.config import logger

from app.schemas.orchestration import AgentDetail # AgentDetail ìŠ¤í‚¤ë§ˆ ì¶”ê°€
from app.schemas.discussion import VoteContent
import re

# ì—ì´ì „íŠ¸ ë° ë„êµ¬ ì‹¤í–‰ì„ ìœ„í•œ LangChain ëª¨ë“ˆ ì„í¬íŠ¸
from langchain.agents import AgentExecutor, create_tool_calling_agent
from app.tools.search import available_tools

# ReAct íŒ¨í„´ì„ ì ìš©í•œ ê°•ë ¥í•œ ì‹œìŠ¤í…œ ë ˆë²¨ ë„êµ¬ ì‚¬ìš© ê·œì¹™ ì •ì˜
SYSTEM_TOOL_INSTRUCTION_BLOCK = """
---
### Tools Guide (VERY IMPORTANT)

You have access to the following tools. You must adhere to the following strict process for using them:

1.  **THOUGHT:** First, analyze the user's request, the debate topic, and the conversation history. Critically assess whether your internal knowledge is sufficient and up-to-date. If the topic involves recent events, specific data, or potentially controversial facts, you MUST consider using a tool.
2.  **ACTION:** If you decide to use a tool, you must format your response as a JSON object for the tool call. For example:
    ```json
    {
      "tool": "web_search",
      "tool_input": "Query to search on the web"
    }
    ```

3.  **FINAL ANSWER:** After you have gathered the necessary information from the tool (or decided that no tool is needed), formulate your comprehensive final answer based on all the information available to you.
**CRITICAL RULE:** Do NOT write about your intention to search in your final answer. Do NOT output text like `web_search(...)` or "I will search for...". You must either use the tool correctly by outputting the JSON action or provide a final answer without mentioning the tool.
---
"""

# ì…ì¥ ë³€í™” ë¶„ì„ ê²°ê³¼ Pydantic ëª¨ë¸
class StanceAnalysis(BaseModel):
    change: Literal['ìœ ì§€', 'ê°•í™”', 'ìˆ˜ì •', 'ì•½í™”']
    reason: str

# ê°œë³„ ì—ì´ì „íŠ¸ì˜ ì…ì¥ ë³€í™”ë¥¼ ë¶„ì„í•˜ëŠ” AI í˜¸ì¶œ í•¨ìˆ˜
async def _get_single_stance_change(
    agent_name: str, prev_statement: str, current_statement: str, discussion_id: str, turn_number: int
) -> dict:
    logger.info(f"--- [Stance Analysis] Agent: {agent_name}, Turn: {turn_number} ë¶„ì„ ì‹œì‘ ---")
    try:
        analyst_setting = await AgentSettings.find_one(
            AgentSettings.name == "Stance Analyst", AgentSettings.status == "active"
        )
        # 1. Stance Analyst ì—ì´ì „íŠ¸ë¥¼ DBì—ì„œ ì°¾ì•˜ëŠ”ì§€ í™•ì¸
        if not analyst_setting:
            # logger.warning("!!! [Stance Analysis] 'Stance Analyst' ì—ì´ì „íŠ¸ë¥¼ DBì—ì„œ ì°¾ì„ ìˆ˜ ì—†ê±°ë‚˜ 'active' ìƒíƒœê°€ ì•„ë‹™ë‹ˆë‹¤.")
            return {"agent_name": agent_name, "change": "ë¶„ì„ ë¶ˆê°€", "icon": "â“"}
        # logger.info("'Stance Analyst' ì—ì´ì „íŠ¸ ì„¤ì •ì„ ì„±ê³µì ìœ¼ë¡œ ì°¾ì•˜ìŠµë‹ˆë‹¤.")

        transcript_to_analyze = (
            f"ì—ì´ì „íŠ¸ ì´ë¦„: {agent_name}\n\n"
            f"ì´ì „ ë°œì–¸: \"{prev_statement}\"\n\n"
            f"í˜„ì¬ ë°œì–¸: \"{current_statement}\""
        )
        # 2. AIì—ê²Œ ì „ë‹¬ë  ìµœì¢… í”„ë¡¬í”„íŠ¸ ë‚´ìš©ì„ ë¡œê·¸ë¡œ ì¶œë ¥
        # logger.info(f"--- AIì—ê²Œ ì „ë‹¬ë  í”„ë¡¬í”„íŠ¸ ---\n{transcript_to_analyze}\n---------------------------")

        analyst_agent = ChatGoogleGenerativeAI(model=analyst_setting.config.model)
        structured_llm = analyst_agent.with_structured_output(StanceAnalysis)
        prompt = ChatPromptTemplate.from_messages([
            ("system", analyst_setting.config.prompt),
            ("human", "ë‹¤ìŒ í† ë¡  ëŒ€í™”ë¡ì„ ë¶„ì„í•˜ì„¸ìš”:\n\n{transcript}")
        ])
        chain = prompt | structured_llm
        
        analysis = await chain.ainvoke(
            {"transcript": transcript_to_analyze},
            config={"tags": [f"discussion_id:{discussion_id}", f"turn:{turn_number}", "task:stance_analysis"]}
        )
        
        # 3. AIì˜ ì‘ë‹µì´ ì„±ê³µì ìœ¼ë¡œ íŒŒì‹±ë˜ì—ˆëŠ”ì§€ í™•ì¸
        # logger.info(f"ì„±ê³µì ìœ¼ë¡œ AI ì‘ë‹µì„ íŒŒì‹±í–ˆìŠµë‹ˆë‹¤: {analysis}")
        
        icon_map = {"ìœ ì§€": "ğŸ˜", "ê°•í™”": "ğŸ”¼", "ìˆ˜ì •": "ğŸ”„", "ì•½í™”": "ğŸ”½"}
        return {"agent_name": agent_name, "change": analysis.change, "icon": icon_map.get(analysis.change, "â“")}
    
    except Exception as e:
        # 4. ì˜¤ë¥˜ ë°œìƒ ì‹œ, ì •í™•í•œ ì˜¤ë¥˜ ë©”ì‹œì§€ë¥¼ ë¡œê·¸ë¡œ ì¶œë ¥
        logger.error(f"!!! [Stance Analysis] ì—ëŸ¬ ë°œìƒ: Agent '{agent_name}'ì˜ ì…ì¥ ë¶„ì„ ì¤‘ ì‹¤íŒ¨. ì—ëŸ¬: {e}", exc_info=True)
        return {"agent_name": agent_name, "change": "ë¶„ì„ ë¶ˆê°€", "icon": "â“"}

# ëª¨ë“  ì°¸ì—¬ìì˜ ì…ì¥ ë³€í™”ë¥¼ ë³‘ë ¬ë¡œ ë¶„ì„í•˜ëŠ” ë©”ì¸ í•¨ìˆ˜
async def _analyze_stance_changes(transcript: List[dict], jury_members: List[dict], discussion_id: str, turn_number: int) -> List[dict]:
    num_jury = len(jury_members)
    # logger.info(f"--- [Stance Analysis] ì…ì¥ ë³€í™” ë¶„ì„ ì‹œì‘. Turn: {turn_number}, Transcript Lenth: {len(transcript)}, Jury Members: {num_jury} ---")
    
    # 1. ë¶„ì„ì„ ì‹¤í–‰í•  ì¡°ê±´ì´ ë§ëŠ”ì§€ í™•ì¸
    if turn_number < 1 or len(transcript) < num_jury * 2:
        # logger.warning(f"ë¶„ì„ ì¡°ê±´ ë¯¸ì¶©ì¡±ìœ¼ë¡œ ì…ì¥ ë³€í™” ë¶„ì„ì„ ê±´ë„ˆëœë‹ˆë‹¤. (Turn: {turn_number}, Transcript Lenth: {len(transcript)})")
        return []

    current_round_map = {turn['agent_name']: turn['message'] for turn in transcript[-num_jury:]}
    prev_round_map = {turn['agent_name']: turn['message'] for turn in transcript[-num_jury*2:-num_jury]}

    # 2. ì´ì „ ë¼ìš´ë“œì™€ í˜„ì¬ ë¼ìš´ë“œì˜ ë°œì–¸ì´ ì˜¬ë°”ë¥´ê²Œ ì¶”ì¶œë˜ì—ˆëŠ”ì§€ í™•ì¸
    # logger.info(f"ì´ì „ ë¼ìš´ë“œ ë°œì–¸ì: {list(prev_round_map.keys())}")
    # logger.info(f"í˜„ì¬ ë¼ìš´ë“œ ë°œì–¸ì: {list(current_round_map.keys())}")

    tasks = []
    for agent in jury_members:
        agent_name = agent['name']
        if agent_name in prev_round_map and agent_name in current_round_map:
            task = _get_single_stance_change(
                agent_name, 
                prev_round_map[agent_name], 
                current_round_map[agent_name], 
                discussion_id, 
                turn_number
            )
            tasks.append(task)
        else:
            # 3. íŠ¹ì • ì—ì´ì „íŠ¸ì˜ ë°œì–¸ì´ ëˆ„ë½ë˜ì—ˆëŠ”ì§€ í™•ì¸
            logger.warning(f"!!! '{agent_name}' ì—ì´ì „íŠ¸ì˜ ì´ì „ ë˜ëŠ” í˜„ì¬ ë°œì–¸ì´ ì—†ì–´ ë¶„ì„ì—ì„œ ì œì™¸ë©ë‹ˆë‹¤.")
    
    if not tasks:
        # logger.warning("ë¶„ì„í•  ì—ì´ì „íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return []
        
    results = await asyncio.gather(*tasks)
    # logger.info(f"--- [Stance Analysis] ì…ì¥ ë³€í™” ë¶„ì„ ì™„ë£Œ. ê²°ê³¼ ìˆ˜: {len(results)} ---")
    return results

# ë¼ìš´ë“œ ìš”ì•½ ë¶„ì„ì„ ìœ„í•œ Pydantic ëª¨ë¸
class CriticalUtterance(BaseModel):
    agent_name: str
    message: str

async def _get_round_summary(transcript_str: str, discussion_id: str, turn_number: int) -> dict:
    """ë¼ìš´ë“œ ëŒ€í™”ë¡ì„ ë¶„ì„í•˜ì—¬ ê²°ì •ì  ë°œì–¸ì„ ì„ ì •í•˜ëŠ” AI ì—ì´ì „íŠ¸ë¥¼ í˜¸ì¶œí•©ë‹ˆë‹¤."""
    try:
        # DBì—ì„œ Round Analyst ì—ì´ì „íŠ¸ ì„¤ì •ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.
        analyst_setting = await AgentSettings.find_one(
            AgentSettings.name == "Round Analyst", AgentSettings.status == "active"
        )
        if not analyst_setting: return None

        analyst_agent = ChatGoogleGenerativeAI(model=analyst_setting.config.model)
        structured_llm = analyst_agent.with_structured_output(CriticalUtterance)
        
        prompt = ChatPromptTemplate.from_messages([
            ("system", analyst_setting.config.prompt),
            ("human", "Analyze the following transcript:\n\n{transcript}")
        ])
        
        chain = prompt | structured_llm
        summary = await chain.ainvoke(
            {"transcript": transcript_str},
            config={"tags": [f"discussion_id:{discussion_id}", f"turn:{turn_number}", "task:summarize"]}
        )
        return summary.dict()
    except Exception as e:
        logger.error(f"Error getting round summary: {e}")
        return None

async def _run_single_agent_turn(
    agent_config: dict,
    topic: str,
    history: str,
    evidence: str,
    special_directive: str,
    discussion_id: str,
    turn_count: int
) -> str:
    """ë‹¨ì¼ ì—ì´ì „íŠ¸ì˜ ë°œì–¸(turn)ì„ ìƒì„±í•©ë‹ˆë‹¤. ì—ì´ì „íŠ¸ ì„¤ì •ì— ë”°ë¼ ì›¹ ê²€ìƒ‰ ë„êµ¬ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."""
    agent_name = agent_config.get("name", "Unknown Agent")
    logger.info(f"--- [Flow] Running turn for agent: {agent_name} (Discussion: {discussion_id}, Turn: {turn_count}) ---")

    try:
        llm = ChatGoogleGenerativeAI(
            model=agent_config.get("model", "gemini-1.5-flash"),
            temperature=agent_config.get("temperature", 0.2)
        )

        # í† ë¡  ë¼ìš´ë“œ ìˆ˜ì— ë”°ë¼ ë™ì ìœ¼ë¡œ ì§€ì‹œì‚¬í•­ì„ ë³€ê²½
        human_instruction = (
            "ì§€ê¸ˆì€ 'ëª¨ë‘ ë³€ë¡ ' ì‹œê°„ì…ë‹ˆë‹¤. ìœ„ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ë‹¹ì‹ ì˜ ì´ˆê¸° ì…ì¥ì„ ìµœì†Œ 100ìì—ì„œ ìµœëŒ€ 500ì ì´ë‚´ë¡œ ì„¤ëª…í•´ì£¼ì„¸ìš”."
            if turn_count == 0 else
            f"ì§€ê¸ˆì€ '{turn_count + 1}ì°¨ í† ë¡ ' ì‹œê°„ì…ë‹ˆë‹¤. ì´ì „ì˜ ì—ì´ì „íŠ¸ë“¤ì˜ ì˜ê²¬ì„ ê³ ë ¤í•˜ì—¬ ë‹¤ë¥¸ ì—ì´ì „íŠ¸ì˜ ì£¼ì¥ì„ ë°˜ë°•í•˜ê±°ë‚˜ ë‹¤ë¥¸ ì—ì´ì „íŠ¸ì˜ ì˜ê²¬ì— ì ê·¹ ë™ì¡°í•˜ê±°ë‚˜ ì•„ë‹ˆë©´ ë‹¤ë¥¸ ì—ì´ì „íŠ¸ì˜ ì˜ê²¬ì„ ìˆ˜ë ´í•˜ì—¬ ì˜ê²¬ì„ ìˆ˜ì •í•œ ë‹¹ì‹ ì˜ ì˜ê²¬ì„ ì£¼ì¥í•©ë‹ˆë‹¤. ë‹¤ë¥¸ ì—ì´ì „íŠ¸ì˜ ë…¼ë¦¬ì  ëª¨ìˆœì´ë‚˜ ì‚¬ì‹¤ì— ìœ„ë°°ë˜ëŠ” ì£¼ì¥ì´ ìˆë‹¤ê³  ìƒê°í•œë‹¤ë©´ ì ê·¹ì ìœ¼ë¡œ ë°˜ë°•í•˜ì‹­ì‹œìš”. ë˜í•œ, ë‹¤ë¥¸ ì—ì´ì „íŠ¸ê°€ ìƒê°í•˜ì§€ ëª»í•˜ëŠ” ìƒˆë¡œìš´ ì•„ì´ë””ì–´, ë…ì°½ì ì¸ ì£¼ì¥, ê·¸ë¦¬ê³  í† ë¡ ì˜ ì£¼ì œë¥¼ ì‹¬í™”í•  ìˆ˜ ìˆë‹¤ê³  ìƒê°ë˜ëŠ” ë‚´ìš©ì„ ì ê·¹ì ìœ¼ë¡œ ì£¼ì¥í•©ë‹ˆë‹¤. ë˜í•œ, ì´ì „ í† ë¡  ì°¨ìˆ˜ì—ì„œ ì£¼ì¥í•œ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ìì‹ ì˜ ì£¼ì¥ì¤‘ì— ë³´ë‹¤ êµ¬ì²´ì ì¸ ëŒ€ì•ˆ, êµ¬ì²´ì ì¸ ë°©ì•ˆë“±ìœ¼ë¡œ ìì‹ ì˜ ì£¼ì¥ì„ ì‹¬í™” ë°œì „í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤. í† ë¡ ì˜ ì°¨ìˆ˜ê°€ ë†’ì•„ì§ˆìˆ˜ë¡ ì´ì „ ìì‹ ì˜ ì£¼ì¥ì„ ë™ì–´ë°˜ë³µí•˜ê¸° ë³´ë‹¨ ë³´ë‹¤ êµ¬ì²´ì ì¸ ëŒ€ì•ˆì„ ì£¼ì¥í•©ë‹ˆë‹¤. ì£¼ì¥ì€ ìµœì†Œ 200ì ìµœëŒ€ 500ì ì´ë‚´ë¡œ ì¶”ê°€í•´ì£¼ì„¸ìš”."
        )

        # ìµœì¢… í”„ë¡¬í”„íŠ¸ êµ¬ì„± (ê¸°ì¡´ì˜ ë¶ˆí•„ìš”í•œ ì‹œìŠ¤í…œ ì§€ì‹œì‚¬í•­ ì œê±°)
        final_human_prompt = (
            f"ë‹¹ì‹ ì€ ë‹¤ìŒ í† ë¡ ì— ì°¸ì—¬í•˜ëŠ” AI ì—ì´ì „íŠ¸ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ ì°¸ê³  ìë£Œì™€ í† ë¡  ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ë‹¹ì‹ ì˜ ì„ë¬´ë¥¼ ìˆ˜í–‰í•˜ì„¸ìš”.\n\n"
            f"### ì „ì²´ í† ë¡  ì£¼ì œ: {topic}\n\n"
            f"### ì°¸ê³  ìë£Œ (ì´ˆê¸° ë¶„ì„ ì •ë³´)\n{evidence}\n"
            f"### ì§€ê¸ˆê¹Œì§€ì˜ í† ë¡  ë‚´ìš©:\n{history if history else 'ì•„ì§ í† ë¡  ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤.'}\n\n"
            f"{special_directive}\n"
            f"### ë‹¹ì‹ ì˜ ì„ë¬´\n{human_instruction}"
        )

        logger.info(f"--- [Flow] Agent '{agent_name}' will now decide on tool usage autonomously. ---")
        
        # ReAct ê¸°ë°˜ ë„êµ¬ ì‚¬ìš© ê·œì¹™ì„ ì—ì´ì „íŠ¸ì˜ ì›ë˜ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì•ì— ì¶”ê°€
        original_system_prompt = agent_config.get("prompt", "You are a helpful assistant.")
        tool_system_prompt = SYSTEM_TOOL_INSTRUCTION_BLOCK + "\n\n" + original_system_prompt

        prompt = ChatPromptTemplate.from_messages([
            ("system", tool_system_prompt),
            ("human", "{input}"),
            MessagesPlaceholder(variable_name="agent_scratchpad"),
        ])
        
        tools = [web_search_tool]
        agent = create_tool_calling_agent(llm, tools, prompt)
        agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)
        
        response = await agent_executor.ainvoke(
            {"input": final_human_prompt},
            config={"tags": [f"discussion_id:{discussion_id}", f"agent_name:{agent_name}", f"turn:{turn_count}"]}
        )
        return response.get("output", "ì˜¤ë¥˜: ì‘ë‹µì„ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
    
# í† ë¡  íë¦„ë„ ë¶„ì„ì„ ìœ„í•œ í—¬í¼ í•¨ìˆ˜
def _analyze_flow_data(transcript: List[dict], jury_members: List[dict]) -> dict:
    interactions = []
    agent_names = [agent['name'] for agent in jury_members]
    
    # í˜„ì¬ ë¼ìš´ë“œì˜ ëŒ€í™”ë§Œ ë¶„ì„ (transcriptëŠ” ì „ì²´ ëŒ€í™”ë¡)
    # ê°„ë‹¨í•˜ê²Œ ë§ˆì§€ë§‰ jury_members ìˆ˜ë§Œí¼ì˜ ëŒ€í™”ë§Œ ë¶„ì„
    current_round_transcript = transcript[-len(jury_members):]

    for turn in current_round_transcript:
        speaker = turn['agent_name']
        message = turn['message']
        
        # ë‹¤ë¥¸ ì—ì´ì „íŠ¸ì˜ ì´ë¦„ì´ ì–¸ê¸‰ë˜ì—ˆëŠ”ì§€ í™•ì¸
        for mentioned_agent in agent_names:
            if speaker != mentioned_agent and mentioned_agent in message:
                interactions.append({"from": speaker, "to": mentioned_agent})
                
    return {"interactions": interactions}

# íˆ¬í‘œ ìƒì„±ì„ ìœ„í•œ ë³„ë„ì˜ í—¬í¼ í•¨ìˆ˜
async def _generate_vote_options(transcript_str: str, discussion_id: str, turn_number: int, vote_history: List[str]) -> Optional[dict]:
    """ëŒ€í™”ë¡ê³¼ ì´ì „ íˆ¬í‘œ ê¸°ë¡ì„ ë¶„ì„í•˜ì—¬ ìƒˆë¡œìš´ íˆ¬í‘œ ì£¼ì œì™€ ì„ íƒì§€ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    logger.info(f"--- [Vote Generation] Turn: {turn_number} íˆ¬í‘œ ìƒì„± ì‹œì‘ ---")
    raw_response = ""
    json_str = ""
    try:
        vote_caster_setting = await AgentSettings.find_one(
            AgentSettings.name == "Vote Caster", AgentSettings.status == "active"
        )
        if not vote_caster_setting:
            logger.error("!!! [Vote Generation] 'Vote Caster' ì—ì´ì „íŠ¸ë¥¼ DBì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return None

        # [ìˆ˜ì •] ì´ì „ íˆ¬í‘œ ê¸°ë¡ì„ í”„ë¡¬í”„íŠ¸ì— ëª…í™•í•˜ê²Œ í¬í•¨
        history_prompt_section = "ì•„ì§ ì‚¬ìš©ìì˜ ì´ì „ íˆ¬í‘œ ê¸°ë¡ì´ ì—†ìŠµë‹ˆë‹¤."
        if vote_history:
            history_items = "\n".join([f"- '{item}'" for item in vote_history])
            history_prompt_section = f"### ì´ì „ íˆ¬í‘œì—ì„œ ì‚¬ìš©ìê°€ ì„ íƒí•œ í•­ëª©ë“¤ (ì´ í•­ëª©ë“¤ê³¼ ìœ ì‚¬í•œ ì œì•ˆì€ í”¼í•˜ê³ , ë” ì‹¬í™”ëœ ìƒˆë¡œìš´ ê´€ì ì„ ì œì‹œí•˜ì„¸ìš”):\n{history_items}"

        # [ìˆ˜ì •] í”„ë¡¬í”„íŠ¸ë¥¼ ë” ëª…í™•í•˜ê³  êµ¬ì¡°ì ìœ¼ë¡œ ë³€ê²½
        final_human_prompt = (
            f"{history_prompt_section}\n\n"
            f"### í˜„ì¬ ë¼ìš´ë“œê¹Œì§€ì˜ ì „ì²´ í† ë¡  ëŒ€í™”ë¡:\n{transcript_str}"
        )

        vote_caster_agent = ChatGoogleGenerativeAI(
            model=vote_caster_setting.config.model,
            temperature=vote_caster_setting.config.temperature,
            # [ì¶”ê°€] JSON ì‘ë‹µì„ ë” ì•ˆì •ì ìœ¼ë¡œ ë°›ê¸° ìœ„í•œ ì„¤ì •
            model_kwargs={"response_mime_type": "application/json"}
        )
        
        prompt = ChatPromptTemplate.from_messages([
            ("system", vote_caster_setting.config.prompt),
            ("human", final_human_prompt)
        ])
        
        chain = prompt | vote_caster_agent

        response = await chain.ainvoke(
            {},
            config={"tags": [f"discussion_id:{discussion_id}", f"turn:{turn_number}", "task:generate_vote"]}
        )

        raw_response = response.content
        
        # LLMì´ ë•Œë•Œë¡œ markdown ì½”ë“œ ë¸”ë¡ì„ í¬í•¨í•˜ëŠ” ê²½ìš°ë¥¼ ëŒ€ë¹„í•œ ì•ˆì •ì ì¸ íŒŒì‹± ë¡œì§
        match = re.search(r"```(json)?\s*({.*?})\s*```", raw_response, re.DOTALL)
        json_str = match.group(2) if match else raw_response
        
        # Pydantic ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ìœ íš¨ì„± ê²€ì¦
        vote_content = VoteContent.model_validate_json(json_str)
        
        logger.info(f"--- [Vote Generation] íˆ¬í‘œ ìƒì„± ë° íŒŒì‹± ì™„ë£Œ: {vote_content.topic} ---")
        return vote_content.model_dump()
        
    except (ValidationError, json.JSONDecodeError) as e:
        logger.error(f"!!! [Vote Generation] JSON íŒŒì‹± ì˜¤ë¥˜. ì˜¤ë¥˜: {e}\nì›ë³¸ ì‘ë‹µ: {raw_response}", exc_info=True)
        # íŒŒì‹± ì‹¤íŒ¨ ì‹œ, ì‚¬ìš©ìì—ê²Œ ë‹¤ìŒ ë¼ìš´ë“œë¡œ ë„˜ì–´ê°ˆ ìˆ˜ ìˆëŠ” ê¸°ë³¸ ì˜µì…˜ ì œê³µ
        return {
            "topic": "ë‹¤ìŒìœ¼ë¡œ ì–´ë–¤ í† ë¡ ì„ ì§„í–‰í• ê¹Œìš”?",
            "options": ["ê°€ì¥ ì˜ê²¬ì´ ì—‡ê°ˆë¦¬ëŠ” ìŸì ì— ëŒ€í•´ ì¶”ê°€ ë°˜ë¡ ", "ìƒˆë¡œìš´ ê´€ì ì˜ ì „ë¬¸ê°€ ì¶”ê°€ íˆ¬ì… ìš”ì²­", "í˜„ì¬ê¹Œì§€ ë‚´ìš© ì¤‘ê°„ ìš”ì•½"]
        }
    except Exception as e:
        logger.error(f"!!! [Vote Generation] íˆ¬í‘œ ìƒì„± ì¤‘ ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜ ë°œìƒ: {e}", exc_info=True)
        return None
    
async def execute_turn(discussion_log: DiscussionLog, user_vote: Optional[str] = None):
    """
    ë°±ê·¸ë¼ìš´ë“œì—ì„œ ë‹¨ì¼ í† ë¡  í„´ì„ ì‹¤í–‰í•˜ê³ , ê²°ê³¼ë¥¼ DBì— ê¸°ë¡í•©ë‹ˆë‹¤.
    ì‚¬ìš©ìì˜ íˆ¬í‘œ ê¸°ë¡ì€ Redisë¥¼ í†µí•´ ì„¸ì…˜ìœ¼ë¡œ ê´€ë¦¬í•©ë‹ˆë‹¤.
    """
    logger.info(f"--- [BG Task] Executing turn for Discussion ID: {discussion_log.discussion_id} ---")
    
    redis_key = f"vote_history:{discussion_log.discussion_id}"
    vote_history = []
    try:
        history_json = await db.redis_client.get(redis_key)
        if history_json:
            vote_history = json.loads(history_json)
    except Exception as e:
        logger.error(f"!!! [Redis Error] Redisì—ì„œ íˆ¬í‘œ ê¸°ë¡ì„ ê°€ì ¸ì˜¤ëŠ” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}", exc_info=True)

    if user_vote:
        vote_history.append(user_vote)
        try:
            await db.redis_client.set(redis_key, json.dumps(vote_history), ex=86400)
            logger.info(f"--- [BG Task] ì‚¬ìš©ì íˆ¬í‘œ '{user_vote}'ë¥¼ Redisì— ê¸°ë¡í–ˆìŠµë‹ˆë‹¤. í˜„ì¬ ê¸°ë¡: {vote_history} ---")
        except Exception as e:
            logger.error(f"!!! [Redis Error] Redisì— íˆ¬í‘œ ê¸°ë¡ì„ ì €ì¥í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}", exc_info=True)

    current_turn = discussion_log.turn_number
    history_str = "\n\n".join([f"{t['agent_name']}: {t['message']}" for t in discussion_log.transcript])

    # DBì— ì €ì¥ëœ ì¦ê±° ìë£Œë¥¼ ë¶ˆëŸ¬ì™€ í”„ë¡¬í”„íŠ¸ì— í¬í•¨í•  ë¬¸ìì—´ë¡œ ë§Œë“­ë‹ˆë‹¤.
    evidence_str = ""
    if discussion_log.evidence_briefing:
        web_evidence = "\n".join([f"- {item['summary']} (ì¶œì²˜: {item['source']})" for item in discussion_log.evidence_briefing.get('web_evidence', [])])
        file_evidence = "\n".join([f"- {item['summary']} (ì¶œì²˜: {item['source']})" for item in discussion_log.evidence_briefing.get('file_evidence', [])])
        
        evidence_str += "--- [ì°¸ê³  ìë£Œ: ì›¹ ê²€ìƒ‰ ê²°ê³¼ ìš”ì•½] ---\n"
        evidence_str += web_evidence + "\n" if web_evidence else "ê´€ë ¨ ì›¹ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.\n"
        evidence_str += "--- [ì°¸ê³  ìë£Œ: ì œì¶œ íŒŒì¼ ìš”ì•½] ---\n"
        evidence_str += file_evidence + "\n" if file_evidence else "ì œì¶œëœ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.\n"


    special_directive = ""
    if user_vote:
        special_directive = (
            f"\n\n--- íŠ¹ë³„ ì§€ì‹œë¬¸ ---\n"
            f"ì‚¬ìš©ìëŠ” ì§ì „ ë¼ìš´ë“œì—ì„œ '{user_vote}' ê´€ì ì— ëŒ€í•œ ë‹¹ì‹ ì˜ ì˜ê²¬ì„ ë“£ê³ ì‹¶ì–´í•©ë‹ˆë‹¤."
            f"ì´ ê´€ì ì„ í¬í•¨í•˜ì—¬ ë‹¹ì‹ ì˜ ì£¼ì¥ì„ ê°•í™” ë˜ëŠ” ìˆ˜ì •í•˜ê±°ë‚˜ ë‹¤ë¥¸ ì—ì´ì „íŠ¸ë“¤ì˜ ì£¼ì¥ì„ ë°˜ë°•í•˜ì‹­ì‹œì˜¤."
            f"ê·¸ëŸ¬ë‚˜ ì´ ê´€ì ì´ ë‹¹ì‹ ì˜ ìƒê°ì— ì¤‘ìš”í•˜ì§€ ì•Šë‹¤ë©´ ì´ í† ë¡ ì´ ì–´ë–¤ ë°©í–¥ì— ì¤‘ì ì„ ë‘ì–´ì•¼ í•˜ëŠ”ì§€ ì•ìœ¼ë¡œ ì–´ë–¤ ë…¼ì˜ë¥¼ ì‹¬í™” ë°œì „ì‹œì¼œì•¼ í•˜ëŠ”ì§€ ì˜¤íˆë ¤ ì ê·¹ì ìœ¼ë¡œ ë‹¹ì‹ ì˜ ì£¼ì¥ì„ í¼ì¹ ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤."
            f"\n-------------------\n"
        )

    excluded_roles = ["ì¬íŒê´€", "ì‚¬íšŒì"]
    jury_members = [p for p in discussion_log.participants if p.get('name') not in excluded_roles]

    # --- [í•µì‹¬ ìˆ˜ì •] ì—ì´ì „íŠ¸ ë°œì–¸ì„ ìˆœì°¨ ì‹¤í–‰ì—ì„œ ë™ì‹œ ì‹¤í–‰ìœ¼ë¡œ ë³€ê²½ ---

    # 1. ëª¨ë“  ì—ì´ì „íŠ¸ì˜ ë¹„ë™ê¸° ì‘ì—…ì„ ë‹´ì„ ë¦¬ìŠ¤íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    tasks = []
    for agent_config in jury_members:
        # 2. awaitë¡œ ì¦‰ì‹œ ì‹¤í–‰í•˜ëŠ” ëŒ€ì‹ , ì‹¤í–‰í•  ì‘ì—…(ì½”ë£¨í‹´)ì„ ë§Œë“¤ì–´ tasks ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€í•©ë‹ˆë‹¤.
        task = _run_single_agent_turn(
            agent_config, 
            discussion_log.topic, 
            history_str, 
            evidence_str,  # ì¦ê±° ìë£Œ ì „ë‹¬
            special_directive,
            discussion_log.discussion_id,
            current_turn
        )
        tasks.append(task)

    # 3. asyncio.gatherë¥¼ ì‚¬ìš©í•´ ëª¨ë“  ì‘ì—…ì„ ë™ì‹œì— ì‹¤í–‰í•˜ê³ , ëª¨ë“  ê²°ê³¼ê°€ ë„ì°©í•  ë•Œê¹Œì§€ ê¸°ë‹¤ë¦½ë‹ˆë‹¤.
    logger.info(f"--- [BG Task] {len(tasks)}ëª…ì˜ ì—ì´ì „íŠ¸ ë°œì–¸ì„ ë™ì‹œì— ìƒì„± ì‹œì‘... (ID: {discussion_log.discussion_id})")
    messages = await asyncio.gather(*tasks)
    logger.info(f"--- [BG Task] ëª¨ë“  ì—ì´ì „íŠ¸ ë°œì–¸ ìƒì„± ì™„ë£Œ. (ID: {discussion_log.discussion_id})")

    # 4. ì´ì œ ëª¨ë“  ë‹µë³€ì´ ë„ì°©í–ˆìœ¼ë¯€ë¡œ, ê²°ê³¼ë¥¼ ìˆœì„œëŒ€ë¡œ transcriptì— ì¶”ê°€í•©ë‹ˆë‹¤.
    for i, message in enumerate(messages):
        agent_name = jury_members[i]['name']
        turn_data = {"agent_name": agent_name, "message": message, "timestamp": datetime.utcnow()}
        discussion_log.transcript.append(turn_data)

    # --- [ìˆ˜ì • ì™„ë£Œ] ---
        
    logger.info(f"--- [BG Task] ë¼ìš´ë“œ {current_turn} ì™„ë£Œ. ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤... (ID: {discussion_log.discussion_id})")
    
    # ë¶„ì„ì— í•„ìš”í•œ ìµœì‹  ëŒ€í™”ë¡ ë¬¸ìì—´ ìƒì„± (ì´ë²ˆ ë¼ìš´ë“œ ë°œì–¸ë§Œ)
    final_transcript_str = "\n\n".join([f"{t['agent_name']}: {t['message']}" for t in discussion_log.transcript[-len(jury_members):]])
    
    analysis_tasks = {
        "round_summary": _get_round_summary(final_transcript_str, discussion_log.discussion_id, discussion_log.turn_number),
        "stance_changes": _analyze_stance_changes(discussion_log.transcript, jury_members, discussion_log.discussion_id, discussion_log.turn_number),
        "flow_data": asyncio.to_thread(_analyze_flow_data, discussion_log.transcript, jury_members)
    }
    
    analysis_results = await asyncio.gather(*analysis_tasks.values())
    analysis_map = dict(zip(analysis_tasks.keys(), analysis_results))

    discussion_log.round_summary = {
        "critical_utterance": analysis_map.get("round_summary"),
        "stance_changes": analysis_map.get("stance_changes")
    }
    discussion_log.flow_data = analysis_map.get("flow_data")

    logger.info(f"--- [BG Task] ë¶„ì„ ì™„ë£Œ. ê²°ê³¼ë¥¼ DBì— ì €ì¥í•©ë‹ˆë‹¤. (ID: {discussion_log.discussion_id})")
    
    # ë‹¤ìŒ ë¼ìš´ë“œë¥¼ ìœ„í•œ íˆ¬í‘œ ìƒì„±
    full_history_str = "\n\n".join([f"{t['agent_name']}: {t['message']}" for t in discussion_log.transcript])
    discussion_log.current_vote = await _generate_vote_options(
        full_history_str, 
        discussion_log.discussion_id, 
        discussion_log.turn_number,
        vote_history
    )
    
    discussion_log.status = "waiting_for_vote"
    discussion_log.turn_number += 1
    
    await discussion_log.save()
    
    logger.info(f"--- [BG Task] Turn completed for {discussion_log.discussion_id}. New status: '{discussion_log.status}' ---")