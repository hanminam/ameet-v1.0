# src/app/services/discussion_flow.py
# ë¯¸ë˜ì— êµ¬í˜„ë  ë³µì¡í•œ í† ë¡  ë¡œì§ì„ ì„ì‹œë¡œ ëŒ€ì²´í•˜ëŠ” 'ê¸°ëŠ¥ì ì¸ ëª©ì—…(Functional Mock)' 

import asyncio
from typing import List, Literal, Optional
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.prompts import ChatPromptTemplate
from datetime import datetime

from pydantic import BaseModel

from app.schemas.orchestration import DebateTeam
from app.models.discussion import AgentSettings, DiscussionLog
from app.core.config import logger

from app.schemas.orchestration import AgentDetail # AgentDetail ìŠ¤í‚¤ë§ˆ ì¶”ê°€

# ì…ì¥ ë³€í™” ë¶„ì„ ê²°ê³¼ Pydantic ëª¨ë¸
class StanceAnalysis(BaseModel):
    change: Literal['ìœ ì§€', 'ê°•í™”', 'ìˆ˜ì •', 'ì•½í™”']
    reason: str

# ê°œë³„ ì—ì´ì „íŠ¸ì˜ ì…ì¥ ë³€í™”ë¥¼ ë¶„ì„í•˜ëŠ” AI í˜¸ì¶œ í•¨ìˆ˜
async def _get_single_stance_change(
    agent_name: str, prev_statement: str, current_statement: str, discussion_id: str, turn_number: int
) -> dict:
    try:
        analyst_setting = await AgentSettings.find_one(
            AgentSettings.name == "Stance Analyst", AgentSettings.status == "active"
        )
        if not analyst_setting: return {"agent_name": agent_name, "change": "ë¶„ì„ ë¶ˆê°€", "icon": "â“"}

        analyst_agent = ChatGoogleGenerativeAI(model=analyst_setting.config.model)
        structured_llm = analyst_agent.with_structured_output(StanceAnalysis)
        prompt = ChatPromptTemplate.from_messages([
            ("system", analyst_setting.config.prompt),
            ("human", "ë‹¤ìŒ í† ë¡  ëŒ€í™”ë¡ì„ ë¶„ì„í•˜ì„¸ìš”:\n\n{transcript}")
        ])
        chain = prompt | structured_llm
        analysis = await chain.ainvoke(
            {}, config={"tags": [f"discussion_id:{discussion_id}", f"turn:{turn_number}", "task:stance_analysis"]}
        )
        
        icon_map = {"ìœ ì§€": "ğŸ˜", "ê°•í™”": "ğŸ”¼", "ìˆ˜ì •": "ğŸ”„", "ì•½í™”": "ğŸ”½"}
        return {"agent_name": agent_name, "change": analysis.change, "icon": icon_map.get(analysis.change, "â“")}
    except Exception:
        return {"agent_name": agent_name, "change": "ë¶„ì„ ë¶ˆê°€", "icon": "â“"}

# ëª¨ë“  ì°¸ì—¬ìì˜ ì…ì¥ ë³€í™”ë¥¼ ë³‘ë ¬ë¡œ ë¶„ì„í•˜ëŠ” ë©”ì¸ í•¨ìˆ˜
async def _analyze_stance_changes(transcript: List[dict], jury_members: List[dict], discussion_id: str, turn_number: int) -> List[dict]:
    num_jury = len(jury_members)
    # ë¹„êµí•  ì´ì „ ë¼ìš´ë“œê°€ ì—†ìœ¼ë©´ ë¹ˆ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜
    if turn_number < 1 or len(transcript) < num_jury * 2:
        return []

    # í˜„ì¬ ë¼ìš´ë“œì™€ ì´ì „ ë¼ìš´ë“œì˜ ë°œì–¸ì„ ì—ì´ì „íŠ¸ ì´ë¦„ìœ¼ë¡œ ë§¤í•‘
    current_round_map = {turn['agent_name']: turn['message'] for turn in transcript[-num_jury:]}
    prev_round_map = {turn['agent_name']: turn['message'] for turn in transcript[-num_jury*2:-num_jury]}

    tasks = []
    for agent in jury_members:
        agent_name = agent['name']
        # ë‘ ë¼ìš´ë“œ ëª¨ë‘ì— ë°œì–¸ì´ ìˆëŠ” ì—ì´ì „íŠ¸ë§Œ ë¶„ì„ ëŒ€ìƒìœ¼ë¡œ ì¶”ê°€
        if agent_name in prev_round_map and agent_name in current_round_map:
            task = _get_single_stance_change(
                agent_name, 
                prev_round_map[agent_name], 
                current_round_map[agent_name], 
                discussion_id, 
                turn_number
            )
            tasks.append(task)
    
    if not tasks:
        return []
    return await asyncio.gather(*tasks)

# ë¼ìš´ë“œ ìš”ì•½ ë¶„ì„ì„ ìœ„í•œ Pydantic ëª¨ë¸
class CriticalUtterance(BaseModel):
    agent_name: str
    message: str

async def _get_round_summary(transcript_str: str, discussion_id: str, turn_number: int) -> dict:
    """ë¼ìš´ë“œ ëŒ€í™”ë¡ì„ ë¶„ì„í•˜ì—¬ ê²°ì •ì  ë°œì–¸ì„ ì„ ì •í•˜ëŠ” AI ì—ì´ì „íŠ¸ë¥¼ í˜¸ì¶œí•©ë‹ˆë‹¤."""
    try:
        # DBì—ì„œ Round Analyst ì—ì´ì „íŠ¸ ì„¤ì •ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.
        analyst_setting = await AgentSettings.find_one(
            AgentSettings.name == "Round Analyst", AgentSettings.status == "active"
        )
        if not analyst_setting: return None

        analyst_agent = ChatGoogleGenerativeAI(model=analyst_setting.config.model)
        structured_llm = analyst_agent.with_structured_output(CriticalUtterance)
        
        prompt = ChatPromptTemplate.from_messages([
            ("system", analyst_setting.config.prompt),
            ("human", "Analyze the following transcript:\n\n{transcript}")
        ])
        
        chain = prompt | structured_llm
        summary = await chain.ainvoke(
            {"transcript": transcript_str},
            config={"tags": [f"discussion_id:{discussion_id}", f"turn:{turn_number}", "task:summarize"]}
        )
        return summary.dict()
    except Exception as e:
        logger.error(f"Error getting round summary: {e}")
        return None

async def _run_single_agent_turn(
    agent_config: dict, 
    topic: str, 
    history: str, 
    special_directive: str, 
    discussion_id: str,
    turn_count: int
) -> str:
    """ë‹¨ì¼ ì—ì´ì „íŠ¸ì˜ ë°œì–¸(turn)ì„ ìƒì„±í•©ë‹ˆë‹¤."""
    agent_name = agent_config.get("name", "Unknown Agent")
    logger.info(f"--- [Flow] Running turn for agent: {agent_name} (Discussion: {discussion_id}, Turn: {turn_count}) ---")
    
    try:
        llm = ChatGoogleGenerativeAI(
            model=agent_config.get("model", "gemini-1.5-flash"),
            temperature=agent_config.get("temperature", 0.2)
        )
        
        # [ìˆ˜ì •] í† ë¡  ë¼ìš´ë“œ ìˆ˜ì— ë”°ë¼ ë™ì ìœ¼ë¡œ ì§€ì‹œì‚¬í•­ì„ ë³€ê²½
        if turn_count == 0:  # ì²« ë²ˆì§¸ ë¼ìš´ë“œ (ëª¨ë‘ ë³€ë¡ )
            human_instruction = "ì§€ê¸ˆì€ 'ëª¨ë‘ ë³€ë¡ ' ì‹œê°„ì…ë‹ˆë‹¤. ìœ„ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ë‹¹ì‹ ì˜ ì´ˆê¸° ì…ì¥ì„ ìµœì†Œ 200ìì—ì„œ ìµœëŒ€ 1000ì ì´ë‚´ë¡œ ì„¤ëª…í•´ì£¼ì„¸ìš”."
        else:  # ë‘ ë²ˆì§¸ ë¼ìš´ë“œ ì´í›„ (ë°˜ë¡ )
            human_instruction = f"ì§€ê¸ˆì€ '{turn_count + 1}ì°¨ í† ë¡ ' ì‹œê°„ì…ë‹ˆë‹¤. ì´ì „ì˜ ì—ì´ì „íŠ¸ë“¤ì˜ ì˜ê²¬ì„ ê³ ë ¤í•˜ì—¬ ë‹¤ë¥¸ ì—ì´ì „íŠ¸ì˜ ì£¼ì¥ì„ ë°˜ë°•í•˜ê±°ë‚˜ ë‹¤ë¥¸ ì—ì´ì „íŠ¸ì˜ ì˜ê²¬ì— ì ê·¹ ë™ì¡°í•˜ê±°ë‚˜ ì•„ë‹ˆë©´ ë‹¤ë¥¸ ì—ì´ì „íŠ¸ì˜ ì˜ê²¬ì„ ìˆ˜ë ´í•˜ì—¬ ì˜ê²¬ì„ ìˆ˜ì •í•œ ë‹¹ì‹ ì˜ ì˜ê²¬ì„ ìµœì†Œ 100ì ìµœëŒ€ 500ì ì´ë‚´ë¡œ ì¶”ê°€í•´ì£¼ì„¸ìš”."

        # ìµœì¢… í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        final_human_prompt = (
            f"ì£¼ì œ: {topic}\n\n"
            f"ì§€ê¸ˆê¹Œì§€ì˜ í† ë¡  ë‚´ìš©:\n{history}\n\n"
            f"{special_directive}\n"
            f"{human_instruction}"
        )

        prompt = ChatPromptTemplate.from_messages([
            ("system", agent_config.get("prompt", "You are a helpful assistant.")),
            ("human", final_human_prompt)
        ])
        
        chain = prompt | llm
        
        response = await chain.ainvoke(
            {"topic": topic, "history": history, "special_directive": special_directive},
            config={"tags": [f"discussion_id:{discussion_id}", f"agent_name:{agent_name}", f"turn:{turn_count}"]}
        )
        
        return response.content
        
    except Exception as e:
        logger.error(f"--- [Flow Error] Agent '{agent_name}' turn failed: {e} ---")
        return f"({agent_name} ë°œì–¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ)"
    
# í† ë¡  íë¦„ë„ ë¶„ì„ì„ ìœ„í•œ í—¬í¼ í•¨ìˆ˜
def _analyze_flow_data(transcript: List[dict], jury_members: List[dict]) -> dict:
    interactions = []
    agent_names = [agent['name'] for agent in jury_members]
    
    # í˜„ì¬ ë¼ìš´ë“œì˜ ëŒ€í™”ë§Œ ë¶„ì„ (transcriptëŠ” ì „ì²´ ëŒ€í™”ë¡)
    # ê°„ë‹¨í•˜ê²Œ ë§ˆì§€ë§‰ jury_members ìˆ˜ë§Œí¼ì˜ ëŒ€í™”ë§Œ ë¶„ì„
    current_round_transcript = transcript[-len(jury_members):]

    for turn in current_round_transcript:
        speaker = turn['agent_name']
        message = turn['message']
        
        # ë‹¤ë¥¸ ì—ì´ì „íŠ¸ì˜ ì´ë¦„ì´ ì–¸ê¸‰ë˜ì—ˆëŠ”ì§€ í™•ì¸
        for mentioned_agent in agent_names:
            if speaker != mentioned_agent and mentioned_agent in message:
                interactions.append({"from": speaker, "to": mentioned_agent})
                
    return {"interactions": interactions}
    
async def execute_turn(discussion_log: DiscussionLog, user_vote: Optional[str] = None):
    """
    ë°±ê·¸ë¼ìš´ë“œì—ì„œ ë‹¨ì¼ í† ë¡  í„´ì„ ì‹¤í–‰í•˜ê³ , ê²°ê³¼ë¥¼ DBì— ê¸°ë¡í•©ë‹ˆë‹¤.
    """
    logger.info(f"--- [BG Task] Executing turn for Discussion ID: {discussion_log.discussion_id} ---")
    
    current_turn = discussion_log.turn_number  # [ìˆ˜ì •] DBì—ì„œ í˜„ì¬ í„´ ë²ˆí˜¸ë¥¼ ê°€ì ¸ì˜´

    # 1. ì»¨í…ìŠ¤íŠ¸ ì¤€ë¹„
    current_transcript = [f"{t['agent_name']}: {t['message']}" for t in discussion_log.transcript]
    history_str = "\n\n".join(current_transcript)

    # 2. 'íŠ¹ë³„ ì§€ì‹œë¬¸' ìƒì„±
    special_directive = ""
    if user_vote:
        special_directive = (
            f"\n\n--- íŠ¹ë³„ ì§€ì‹œë¬¸ ---\n"
            f"ì‚¬ìš©ìëŠ” ì§ì „ ë¼ìš´ë“œì—ì„œ '{user_vote}' ê´€ì ì„ ë” ì¤‘ìš”í•˜ê²Œ ì„ íƒí–ˆìŠµë‹ˆë‹¤. "
            f"ì´ ê´€ì ì„ ì¤‘ì‹¬ìœ¼ë¡œ ë‹¹ì‹ ì˜ ì£¼ì¥ì„ ê°•í™”í•˜ê±°ë‚˜ ìƒëŒ€ë°©ì˜ ì£¼ì¥ì„ ë°˜ë°•í•˜ì‹­ì‹œì˜¤."
            f"\n-------------------\n"
        )
    
    # 3. ì—ì´ì „íŠ¸ ìˆœì°¨ ì‹¤í–‰
    excluded_roles = ["ì¬íŒê´€", "ì‚¬íšŒì"]
    jury_members = [p for p in discussion_log.participants if p.get('name') not in excluded_roles]

    for agent_config in jury_members:
        message = await _run_single_agent_turn(
            agent_config, 
            discussion_log.topic, 
            history_str, 
            special_directive,
            discussion_log.discussion_id,
            current_turn  # í˜„ì¬ í„´ ë²ˆí˜¸ë¥¼ ì¸ìë¡œ ì „ë‹¬
        )
        
        # 4. ì‹¤ì‹œê°„ DB ì—…ë°ì´íŠ¸
        turn_data = {
            "agent_name": agent_config['name'], 
            "message": message, 
            "timestamp": datetime.utcnow()
        }
        discussion_log.transcript.append(turn_data)
        await discussion_log.save()
        
        history_str += f"\n\n{agent_config['name']}: {message}"
        await asyncio.sleep(1)

    # ë¼ìš´ë“œ ì¢…ë£Œ í›„ UX ë°ì´í„° ìƒì„± (MVP ë‹¨ê³„ì—ì„œëŠ” ëª©ì—… ë°ì´í„° ì‚¬ìš©)
    if jury_members and discussion_log.transcript:
        transcript_for_summary = "\n".join([f"{t['agent_name']}: {t['message']}" for t in discussion_log.transcript])
        
        # 1. ê²°ì •ì  ë°œì–¸ ì„ ì • (AI í˜¸ì¶œ + Fallback)
        critical_utterance_data = await _get_round_summary(transcript_for_summary, discussion_log.discussion_id, discussion_log.turn_number)
        if not critical_utterance_data: # AI í˜¸ì¶œ ì‹¤íŒ¨ ì‹œ
            current_round_transcript = discussion_log.transcript[-len(jury_members):]
            # ê°€ì¥ ê¸´ ë°œì–¸ì„ ê²°ì •ì  ë°œì–¸ìœ¼ë¡œ ì„ ì •
            longest_turn = max(current_round_transcript, key=lambda x: len(x['message']))
            critical_utterance_data = {
                "agent_name": longest_turn['agent_name'],
                "message": (longest_turn['message'][:80] + "...") if len(longest_turn['message']) > 80 else longest_turn['message']
            }

        # 2. ì…ì¥ ë³€í™” ë°ì´í„° ìƒì„± (AI ê¸°ë°˜ ë¶„ì„)
        stance_changes_data = await _analyze_stance_changes(
            discussion_log.transcript, jury_members, discussion_log.discussion_id, discussion_log.turn_number
        )
        discussion_log.round_summary = {
            "critical_utterance": critical_utterance_data,
            "stance_changes": stance_changes_data
        }

        # 3. í† ë¡  íë¦„ë„ ë°ì´í„° ìƒì„± (ëŒ€í™” ë‚´ìš© ê¸°ë°˜)
        discussion_log.flow_data = _analyze_flow_data(discussion_log.transcript, jury_members)

    # 5. ìµœì¢… ìƒíƒœ ë³€ê²½
    discussion_log.status = "waiting_for_vote"
    discussion_log.turn_number += 1
    await discussion_log.save()
    
    logger.info(f"--- [BG Task] Turn completed for {discussion_log.discussion_id}. New status: '{discussion_log.status}' ---")


async def run_discussion_flow(discussion_id: str, debate_team: DebateTeam, topic: str):
    """
    ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì „ì²´ í† ë¡  íë¦„ì„ ì‹¤í–‰í•˜ê³ , ê° ë°œì–¸ì„ DBì— ê¸°ë¡í•©ë‹ˆë‹¤.
    """
    logger.info(f"--- [Flow BG Task] Started for Discussion ID: {discussion_id} ---")
    
    discussion_log = await DiscussionLog.find_one(DiscussionLog.discussion_id == discussion_id)
    if not discussion_log:
        logger.error(f"--- [Flow BG Task Error] DiscussionLog not found for ID: {discussion_id} ---")
        return

    current_transcript = []
    
    # 1. ëª¨ë‘ ë³€ë¡  (Opening Statements)
    logger.info(f"--- [Flow] Starting Opening Statements for {discussion_id} ---")
    history_str = "í† ë¡ ì´ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤. ê°ì ì˜ê²¬ì„ ë§ì”€í•´ì£¼ì„¸ìš”."
    
    # ì—ì´ì „íŠ¸ë“¤ì„ ìˆœì°¨ì ìœ¼ë¡œ ì‹¤í–‰ (ë³‘ë ¬ ì‹¤í–‰ë„ ê°€ëŠ¥í•˜ë‚˜, ìˆœì°¨ ì§„í–‰ì´ í† ë¡  íë¦„ì— ë” ì í•©)
    for agent_detail in debate_team.jury:
        # DBì—ì„œ ìµœì‹  active ì„¤ì •ì„ ë‹¤ì‹œ ê°€ì ¸ì˜¤ëŠ” ê²ƒì´ ë” ì •í™•í•˜ì§€ë§Œ, MVPì—ì„œëŠ” ì „ë‹¬ë°›ì€ config ì‚¬ìš©
        agent_config = {
            "prompt": agent_detail.prompt,
            "model": agent_detail.model,
            "temperature": agent_detail.temperature
        }

        message = await _run_single_agent_turn(
            agent_detail.name, agent_config, topic, history_str, discussion_id
        )
        
        # DBì— ë°œì–¸ ê¸°ë¡
        turn_data = {"agent_name": agent_detail.name, "message": message, "timestamp": datetime.utcnow()}
        discussion_log.transcript.append(turn_data)
        await discussion_log.save()
        
        # ë‹¤ìŒ ì—ì´ì „íŠ¸ë¥¼ ìœ„í•´ ëŒ€í™” ê¸°ë¡ ì—…ë°ì´íŠ¸
        current_transcript.append(f"{agent_detail.name}: {message}")
        history_str = "\n\n".join(current_transcript)
        
        await asyncio.sleep(1) # ì‹¤ì œ í† ë¡ ì²˜ëŸ¼ ë³´ì´ê²Œ ì•½ê°„ì˜ ë”œë ˆì´

    # 2. ìµœì¢… ê²°ë¡  ë° ìƒíƒœ ì—…ë°ì´íŠ¸ (MVPì—ì„œëŠ” ê°„ë‹¨íˆ ì²˜ë¦¬)
    # TODO: í–¥í›„ 'nì°¨ í† ë¡ ', 'ìµœì¢… ë³€ë¡ ' ë“± ë³µì¡í•œ ë¡œì§ ì¶”ê°€
    
    discussion_log.status = "completed"
    discussion_log.completed_at = datetime.utcnow()
    discussion_log.report_summary = "í† ë¡ ì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤." # ì‹¤ì œ ìš”ì•½ ë¡œì§ ì¶”ê°€ í•„ìš”
    await discussion_log.save()

    logger.info(f"--- [Flow BG Task] Completed for Discussion ID: {discussion_id} ---")